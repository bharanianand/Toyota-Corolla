{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Data Set for ToyotaCorolla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in-set and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso,LinearRegression,Ridge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures, MinMaxScaler\n",
    "from termcolor import colored\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,r2_score,recall_score,precision_score\n",
    "from sklearn.svm import SVR,LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import BaggingRegressor,BaggingClassifier,AdaBoostClassifier,AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def prRed(skk): print(\"\\033[1m \\033[91m {}\\033[00m\" .format(skk)) \n",
    "def prGreen(skk): print(\"\\033[1m \\033[92m {}\\033[00m\" .format(skk)) \n",
    "def prYellow(skk): print(\"\\033[1m \\033[93m {}\\033[00m\" .format(skk)) \n",
    "def prBlack(skk): print(\"\\033[1m \\033[98m {}\\033[00m\" .format(skk)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>...</th>\n",
       "      <th>Central_Lock</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>?TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors</td>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors</td>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                           Model  Price  Age_08_04  \\\n",
       "0   1   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500         23   \n",
       "1   2   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750         23   \n",
       "2   3  ?TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13950         24   \n",
       "3   4   TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  14950         26   \n",
       "4   5     TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors  13750         30   \n",
       "\n",
       "   Mfg_Month  Mfg_Year     KM Fuel_Type    HP  Met_Color  ...  Central_Lock  \\\n",
       "0         10      2002  46986    Diesel   NaN          1  ...             1   \n",
       "1         10      2002  72937    Diesel   NaN          1  ...             1   \n",
       "2          9      2002  41711    Diesel  90.0          1  ...             0   \n",
       "3          7      2002  48000    Diesel  90.0          0  ...             0   \n",
       "4          3      2002  38500    Diesel  90.0          0  ...             1   \n",
       "\n",
       "   Powered_Windows  Power_Steering  Radio  Mistlamps  Sport_Model  \\\n",
       "0                1               1      0          0            0   \n",
       "1                0               1      0          0            0   \n",
       "2                0               1      0          0            0   \n",
       "3                0               1      0          0            0   \n",
       "4                1               1      0          1            0   \n",
       "\n",
       "   Backseat_Divider  Metallic_Rim  Radio_cassette  Tow_Bar  \n",
       "0                 1             0               0        0  \n",
       "1                 1             0               0        0  \n",
       "2                 1             0               0        0  \n",
       "3                 1             0               0        0  \n",
       "4                 1             0               0        0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corolla = pd.read_csv('ToyotaCorolla_kaggle.csv')\n",
    "corolla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>cc</th>\n",
       "      <th>...</th>\n",
       "      <th>Central_Lock</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Age_08_04  Mfg_Month  Mfg_Year     KM Fuel_Type    HP  Met_Color  \\\n",
       "0  13500         23         10      2002  46986    Diesel   NaN          1   \n",
       "1  13750         23         10      2002  72937    Diesel   NaN          1   \n",
       "2  13950         24          9      2002  41711    Diesel  90.0          1   \n",
       "3  14950         26          7      2002  48000    Diesel  90.0          0   \n",
       "4  13750         30          3      2002  38500    Diesel  90.0          0   \n",
       "\n",
       "   Automatic      cc  ...  Central_Lock  Powered_Windows  Power_Steering  \\\n",
       "0          0  2000.0  ...             1                1               1   \n",
       "1          0  2000.0  ...             1                0               1   \n",
       "2          0  2000.0  ...             0                0               1   \n",
       "3          0  2000.0  ...             0                0               1   \n",
       "4          0  2000.0  ...             1                1               1   \n",
       "\n",
       "   Radio  Mistlamps  Sport_Model  Backseat_Divider  Metallic_Rim  \\\n",
       "0      0          0            0                 1             0   \n",
       "1      0          0            0                 1             0   \n",
       "2      0          0            0                 1             0   \n",
       "3      0          0            0                 1             0   \n",
       "4      0          1            0                 1             0   \n",
       "\n",
       "   Radio_cassette  Tow_Bar  \n",
       "0               0        0  \n",
       "1               0        0  \n",
       "2               0        0  \n",
       "3               0        0  \n",
       "4               0        0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corolla.drop(['Id','Model'], axis=1, inplace=True)\n",
    "corolla.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NULL VALUES\n",
    "We have null values in these columns - 'HP' , 'cc' , 'Doors', 'Cylinders', 'Gears', 'Weight'. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price                0\n",
       "Age_08_04            0\n",
       "Mfg_Month            0\n",
       "Mfg_Year             0\n",
       "KM                   0\n",
       "Fuel_Type            0\n",
       "HP                  70\n",
       "Met_Color            0\n",
       "Automatic            0\n",
       "cc                  51\n",
       "Doors               12\n",
       "Cylinders           38\n",
       "Gears               18\n",
       "Quarterly_Tax        0\n",
       "Weight               5\n",
       "Mfr_Guarantee        0\n",
       "BOVAG_Guarantee      0\n",
       "Guarantee_Period     0\n",
       "ABS                  0\n",
       "Airbag_1             0\n",
       "Airbag_2             0\n",
       "Airco                0\n",
       "Automatic_airco      0\n",
       "Boardcomputer        0\n",
       "CD_Player            0\n",
       "Central_Lock         0\n",
       "Powered_Windows      0\n",
       "Power_Steering       0\n",
       "Radio                0\n",
       "Mistlamps            0\n",
       "Sport_Model          0\n",
       "Backseat_Divider     0\n",
       "Metallic_Rim         0\n",
       "Radio_cassette       0\n",
       "Tow_Bar              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corolla.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To impute null values, best categorical column to groupby would be 'Fuel_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>cc</th>\n",
       "      <th>Doors</th>\n",
       "      <th>...</th>\n",
       "      <th>Central_Lock</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNG</th>\n",
       "      <td>7750</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2001</td>\n",
       "      <td>178858</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diesel</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Petrol</th>\n",
       "      <td>21500</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2002</td>\n",
       "      <td>19700</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Price  Age_08_04  Mfg_Month  Mfg_Year      KM     HP  Met_Color  \\\n",
       "Fuel_Type                                                                    \n",
       "CNG         7750         43          2      2001  178858  110.0          0   \n",
       "Diesel     13500         23         10      2002   46986   90.0          1   \n",
       "Petrol     21500         27          6      2002   19700  192.0          0   \n",
       "\n",
       "           Automatic      cc  Doors  ...  Central_Lock  Powered_Windows  \\\n",
       "Fuel_Type                            ...                                  \n",
       "CNG                0  1600.0    3.0  ...             0                0   \n",
       "Diesel             0  2000.0    3.0  ...             1                1   \n",
       "Petrol             0  1800.0    3.0  ...             1                1   \n",
       "\n",
       "           Power_Steering  Radio  Mistlamps  Sport_Model  Backseat_Divider  \\\n",
       "Fuel_Type                                                                    \n",
       "CNG                     1      1          0            0                 1   \n",
       "Diesel                  1      0          0            0                 1   \n",
       "Petrol                  1      1          0            0                 0   \n",
       "\n",
       "           Metallic_Rim  Radio_cassette  Tow_Bar  \n",
       "Fuel_Type                                         \n",
       "CNG                   0               1        0  \n",
       "Diesel                0               0        0  \n",
       "Petrol                1               1        0  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_corolla = corolla.groupby(['Fuel_Type'])\n",
    "g_corolla.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla = g_corolla.transform(lambda grp: grp.fillna(grp.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>cc</th>\n",
       "      <th>Doors</th>\n",
       "      <th>...</th>\n",
       "      <th>Central_Lock</th>\n",
       "      <th>Powered_Windows</th>\n",
       "      <th>Power_Steering</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Tow_Bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>78.306452</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>78.306452</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>7500</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>1998</td>\n",
       "      <td>20544</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>10845</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>1998</td>\n",
       "      <td>19000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>8500</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>1998</td>\n",
       "      <td>17016</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>7250</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>1998</td>\n",
       "      <td>16916</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>6950</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  Age_08_04  Mfg_Month  Mfg_Year     KM          HP  Met_Color  \\\n",
       "0     13500         23         10      2002  46986   78.306452          1   \n",
       "1     13750         23         10      2002  72937   78.306452          1   \n",
       "2     13950         24          9      2002  41711   90.000000          1   \n",
       "3     14950         26          7      2002  48000   90.000000          0   \n",
       "4     13750         30          3      2002  38500   90.000000          0   \n",
       "...     ...        ...        ...       ...    ...         ...        ...   \n",
       "1431   7500         69         12      1998  20544   86.000000          1   \n",
       "1432  10845         72          9      1998  19000   86.000000          0   \n",
       "1433   8500         71         10      1998  17016   86.000000          0   \n",
       "1434   7250         70         11      1998  16916   86.000000          1   \n",
       "1435   6950         76          5      1998      1  110.000000          0   \n",
       "\n",
       "      Automatic      cc  Doors  ...  Central_Lock  Powered_Windows  \\\n",
       "0             0  2000.0    3.0  ...             1                1   \n",
       "1             0  2000.0    3.0  ...             1                0   \n",
       "2             0  2000.0    3.0  ...             0                0   \n",
       "3             0  2000.0    3.0  ...             0                0   \n",
       "4             0  2000.0    3.0  ...             1                1   \n",
       "...         ...     ...    ...  ...           ...              ...   \n",
       "1431          0  1300.0    3.0  ...             1                1   \n",
       "1432          0  1300.0    3.0  ...             0                0   \n",
       "1433          0  1300.0    3.0  ...             0                0   \n",
       "1434          0  1300.0    3.0  ...             0                0   \n",
       "1435          0  1600.0    5.0  ...             0                0   \n",
       "\n",
       "      Power_Steering  Radio  Mistlamps  Sport_Model  Backseat_Divider  \\\n",
       "0                  1      0          0            0                 1   \n",
       "1                  1      0          0            0                 1   \n",
       "2                  1      0          0            0                 1   \n",
       "3                  1      0          0            0                 1   \n",
       "4                  1      0          1            0                 1   \n",
       "...              ...    ...        ...          ...               ...   \n",
       "1431               1      0          1            1                 1   \n",
       "1432               1      0          0            1                 1   \n",
       "1433               1      0          0            0                 1   \n",
       "1434               0      0          0            0                 1   \n",
       "1435               1      0          0            0                 0   \n",
       "\n",
       "      Metallic_Rim  Radio_cassette  Tow_Bar  \n",
       "0                0               0        0  \n",
       "1                0               0        0  \n",
       "2                0               0        0  \n",
       "3                0               0        0  \n",
       "4                0               0        0  \n",
       "...            ...             ...      ...  \n",
       "1431             0               0        0  \n",
       "1432             0               0        0  \n",
       "1433             0               0        0  \n",
       "1434             0               0        0  \n",
       "1435             0               0        0  \n",
       "\n",
       "[1436 rows x 34 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_corolla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group transformation with mean values in the above 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla['HP']=(g_corolla['HP'].apply(lambda grp:grp.fillna(grp.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla['cc']=(g_corolla['cc'].apply(lambda grp:grp.fillna(grp.mean())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla['Doors']=(g_corolla['Doors'].apply(lambda grp:grp.fillna(grp.median())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla['Cylinders']=(g_corolla['Cylinders'].apply(lambda grp:grp.fillna(grp.median())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla['Gears']=(g_corolla['Gears'].apply(lambda grp:grp.fillna(grp.median())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla['Weight']=(g_corolla['Weight'].apply(lambda grp:grp.fillna(grp.mean())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla= pd.concat([g1_corolla,corolla['Fuel_Type']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla = pd.get_dummies(g1_corolla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = g1_corolla['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_corolla.drop('Price', axis=1, inplace=True) #Since it's target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_08_04</th>\n",
       "      <th>Mfg_Month</th>\n",
       "      <th>Mfg_Year</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>Met_Color</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>cc</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>...</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Mistlamps</th>\n",
       "      <th>Sport_Model</th>\n",
       "      <th>Backseat_Divider</th>\n",
       "      <th>Metallic_Rim</th>\n",
       "      <th>Radio_cassette</th>\n",
       "      <th>Tow_Bar</th>\n",
       "      <th>Fuel_Type_CNG</th>\n",
       "      <th>Fuel_Type_Diesel</th>\n",
       "      <th>Fuel_Type_Petrol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>46986</td>\n",
       "      <td>78.306452</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2002</td>\n",
       "      <td>72937</td>\n",
       "      <td>78.306452</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>2002</td>\n",
       "      <td>41711</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>48000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>38500</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_08_04  Mfg_Month  Mfg_Year     KM         HP  Met_Color  Automatic  \\\n",
       "0         23         10      2002  46986  78.306452          1          0   \n",
       "1         23         10      2002  72937  78.306452          1          0   \n",
       "2         24          9      2002  41711  90.000000          1          0   \n",
       "3         26          7      2002  48000  90.000000          0          0   \n",
       "4         30          3      2002  38500  90.000000          0          0   \n",
       "\n",
       "       cc  Doors  Cylinders  ...  Radio  Mistlamps  Sport_Model  \\\n",
       "0  2000.0    3.0        4.0  ...      0          0            0   \n",
       "1  2000.0    3.0        4.0  ...      0          0            0   \n",
       "2  2000.0    3.0        4.0  ...      0          0            0   \n",
       "3  2000.0    3.0        4.0  ...      0          0            0   \n",
       "4  2000.0    3.0        4.0  ...      0          1            0   \n",
       "\n",
       "   Backseat_Divider  Metallic_Rim  Radio_cassette  Tow_Bar  Fuel_Type_CNG  \\\n",
       "0                 1             0               0        0              0   \n",
       "1                 1             0               0        0              0   \n",
       "2                 1             0               0        0              0   \n",
       "3                 1             0               0        0              0   \n",
       "4                 1             0               0        0              0   \n",
       "\n",
       "   Fuel_Type_Diesel  Fuel_Type_Petrol  \n",
       "0                 1                 0  \n",
       "1                 1                 0  \n",
       "2                 1                 0  \n",
       "3                 1                 0  \n",
       "4                 1                 0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_corolla.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selected Standardscaler because of difference in the values sizes and hence needed to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, X_test_org, y_train, y_test = train_test_split(g1_corolla,y1,test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train_org)\n",
    "X_test = sc.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.17930639, -0.75471747, -1.04764096, ..., -0.11053527,\n",
       "        -0.34067899,  0.3623569 ],\n",
       "       [-0.88746902,  0.13556809,  0.86582876, ..., -0.11053527,\n",
       "        -0.34067899,  0.3623569 ],\n",
       "       [-0.03956116, -1.05147933,  0.22800552, ..., -0.11053527,\n",
       "         2.93531454, -2.75971013],\n",
       "       ...,\n",
       "       [ 0.75535246,  1.61937736, -1.04764096, ..., -0.11053527,\n",
       "         2.93531454, -2.75971013],\n",
       "       [-0.30453237,  0.43232994,  0.22800552, ..., -0.11053527,\n",
       "        -0.34067899,  0.3623569 ],\n",
       "       [ 0.64936398, -1.34824118, -0.40981772, ..., -0.11053527,\n",
       "        -0.34067899,  0.3623569 ]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077, 36)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=0, splitter='best'),\n",
       "             iid='False', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5]}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dt_reg = {'max_depth':[1,2,3,4,5]}\n",
    "dt_reg = DecisionTreeRegressor(random_state=0)\n",
    "grid_dt_reg = GridSearchCV(dt_reg,p_dt_reg,cv=3,iid='False')\n",
    "grid_dt_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth : {'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best max_depth :\",grid_dt_reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                             criterion='mse',\n",
       "                                                                             max_depth=5,\n",
       "                                                                             max_features=None,\n",
       "                                                                             max_leaf_nodes=None,\n",
       "                                                                             min_impurity_decrease=0.0,\n",
       "                                                                             min_impurity_split=None,\n",
       "                                                                             min_samples_leaf=1,\n",
       "                                                                             min_samples_split=2,\n",
       "                                                                             min_weight_fraction_leaf=0.0,\n",
       "                                                                             presort='deprecated',\n",
       "                                                                             random_state=0,\n",
       "                                                                             splitter='best'),\n",
       "                                        b...e,\n",
       "                                        bootstrap_features=False,\n",
       "                                        max_features=1.0, max_samples=1.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False),\n",
       "             iid='False', n_jobs=None,\n",
       "             param_grid={'max_features': [2, 5, 10],\n",
       "                         'max_samples': [0.1, 0.5, 1],\n",
       "                         'n_estimators': [100, 200, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_features': [2,5,10] ,'n_estimators': [100, 200, 300, 500],'max_samples': [0.1, 0.5, 1]}\n",
    "dt_reg = DecisionTreeRegressor(max_depth=5,random_state=0)\n",
    "bagging = BaggingRegressor(dt_reg,random_state=0)\n",
    "grid_bag = GridSearchCV(bagging, params, cv=5,iid='False')\n",
    "\n",
    "grid_bag.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "Bagging wiht DT Regressor\u001b[00m\n",
      "Best Params : {'max_features': 10, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Training Score  --> 0.9048272785655762\n",
      "Test Score      --> 0.8312525493300356\n"
     ]
    }
   ],
   "source": [
    "prRed(\"\\nBagging wiht DT Regressor\")\n",
    "print(\"Best Params :\", grid_bag.best_params_)\n",
    "print(\"Training Score  -->\", grid_bag.score(X_train,y_train))\n",
    "print(\"Test Score      -->\", grid_bag.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Project 1, SVR best parameters were already determined as\n",
    "# SVR -> Best parameters: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BaggingRegressor(base_estimator=SVR(C=100,\n",
       "                                                           cache_size=200,\n",
       "                                                           coef0=0.0, degree=3,\n",
       "                                                           epsilon=0.1,\n",
       "                                                           gamma=0.001,\n",
       "                                                           kernel='linear',\n",
       "                                                           max_iter=-1,\n",
       "                                                           shrinking=True,\n",
       "                                                           tol=0.001,\n",
       "                                                           verbose=False),\n",
       "                                        bootstrap=True,\n",
       "                                        bootstrap_features=False,\n",
       "                                        max_features=1.0, max_samples=1.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False),\n",
       "             iid='False', n_jobs=None,\n",
       "             param_grid={'max_features': [2, 5, 10],\n",
       "                         'max_samples': [0.1, 0.5, 1],\n",
       "                         'n_estimators': [100, 200, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_features': [2,5,10] ,'n_estimators': [100,200,300,500],'max_samples': [0.1,0.5,1]}\n",
    "lsvr = SVR(C=100,gamma=0.001,kernel='linear')\n",
    "bagging_lsvr = BaggingRegressor(lsvr,random_state=0)\n",
    "grid_bag_lsvr = GridSearchCV(bagging_lsvr, params, cv=5,iid='False')\n",
    "\n",
    "grid_bag_lsvr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "Bagging with Linear SVR\u001b[00m\n",
      "Best Params : {'max_features': 10, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Training Score  --> 0.8043223862288902\n",
      "Test Score      --> 0.7728180779522372\n"
     ]
    }
   ],
   "source": [
    "prRed(\"\\nBagging with Linear SVR\")\n",
    "print(\"Best Params :\", grid_bag_lsvr.best_params_)\n",
    "print(\"Training Score  -->\", grid_bag_lsvr.score(X_train,y_train))\n",
    "print(\"Test Score      -->\", grid_bag_lsvr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PASTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "Pasting with DT Regressor\u001b[00m\n",
      "Best Params : {'max_features': 10, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Training Score  --> 0.9048272785655762\n",
      "Test Score      --> 0.8312525493300356\n"
     ]
    }
   ],
   "source": [
    "params = {'max_features': [2,5,10] ,'n_estimators': [100, 200, 300, 500],'max_samples': [0.1, 0.5, 1]}\n",
    "dt_reg = DecisionTreeRegressor(max_depth=5,random_state=0)\n",
    "pasting = BaggingRegressor(dt_reg,random_state=0,bootstrap='False')\n",
    "grid_pas = GridSearchCV(pasting, params, cv=5,iid='False')\n",
    "\n",
    "grid_pas.fit(X_train,y_train)\n",
    "\n",
    "prRed(\"\\nPasting with DT Regressor\")\n",
    "print(\"Best Params :\", grid_pas.best_params_)\n",
    "print(\"Training Score  -->\", grid_pas.score(X_train,y_train))\n",
    "print(\"Test Score      -->\", grid_pas.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BaggingRegressor(base_estimator=SVR(C=100,\n",
       "                                                           cache_size=200,\n",
       "                                                           coef0=0.0, degree=3,\n",
       "                                                           epsilon=0.1,\n",
       "                                                           gamma=0.001,\n",
       "                                                           kernel='linear',\n",
       "                                                           max_iter=-1,\n",
       "                                                           shrinking=True,\n",
       "                                                           tol=0.001,\n",
       "                                                           verbose=False),\n",
       "                                        bootstrap='False',\n",
       "                                        bootstrap_features=False,\n",
       "                                        max_features=1.0, max_samples=1.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False),\n",
       "             iid='False', n_jobs=None,\n",
       "             param_grid={'max_features': [2, 5, 10],\n",
       "                         'max_samples': [0.1, 0.5, 1],\n",
       "                         'n_estimators': [100, 200, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_features': [2,5,10] ,'n_estimators': [100,200,300,500],'max_samples': [0.1,0.5,1]}\n",
    "lsvr = SVR(C=100,gamma=0.001,kernel='linear')\n",
    "pasting_lsvr = BaggingRegressor(lsvr,random_state=0,bootstrap='False')\n",
    "grid_pas_lsvr = GridSearchCV(pasting_lsvr, params, cv=5,iid='False')\n",
    "\n",
    "grid_pas_lsvr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "Pasting with Lasso\u001b[00m\n",
      "Best Params : {'max_features': 10, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Training Score  --> 0.8043223862288902\n",
      "Test Score      --> 0.7728180779522372\n"
     ]
    }
   ],
   "source": [
    "prRed(\"\\nPasting with Lasso\")\n",
    "print(\"Best Params :\", grid_pas_lsvr.best_params_)\n",
    "print(\"Training Score  -->\", grid_pas_lsvr.score(X_train,y_train))\n",
    "print(\"Test Score      -->\", grid_pas_lsvr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - As we have already found the best parameters for SVR and Decision Tree Regressor, we will use the same parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with DT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                              criterion='mse',\n",
       "                                                                              max_depth=5,\n",
       "                                                                              max_features=None,\n",
       "                                                                              max_leaf_nodes=None,\n",
       "                                                                              min_impurity_decrease=0.0,\n",
       "                                                                              min_impurity_split=None,\n",
       "                                                                              min_samples_leaf=1,\n",
       "                                                                              min_samples_split=2,\n",
       "                                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                                              presort='deprecated',\n",
       "                                                                              random_state=None,\n",
       "                                                                              splitter='best'),\n",
       "                                         learning_rate=1.0, loss='linear',\n",
       "                                         n_estimators=50, random_state=0),\n",
       "             iid='False', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.25, 0.5, 0.75, 1],\n",
       "                         'n_estimators': [50, 100, 200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': [50, 100, 200, 500],'learning_rate': [0.1, 0.25, 0.5, 0.75, 1]}\n",
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=5), random_state=0)\n",
    "\n",
    "grid_ada = GridSearchCV(ada_reg, params, cv=5, iid='False')\n",
    "grid_ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "AdaBoost Regressor with DT Regressor\u001b[00m\n",
      "Best Params : {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "Training Score  --> 0.9508459766847791\n",
      "Test Score      --> 0.8809075179420086\n"
     ]
    }
   ],
   "source": [
    "prRed(\"\\nAdaBoost Regressor with DT Regressor\")\n",
    "print(\"Best Params :\", grid_ada.best_params_)\n",
    "print(\"Training Score  -->\", grid_ada.score(X_train,y_train))\n",
    "print(\"Test Score      -->\", grid_ada.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostRegressor(base_estimator=SVR(C=100,\n",
       "                                                            cache_size=200,\n",
       "                                                            coef0=0.0, degree=3,\n",
       "                                                            epsilon=0.1,\n",
       "                                                            gamma=0.001,\n",
       "                                                            kernel='linear',\n",
       "                                                            max_iter=-1,\n",
       "                                                            shrinking=True,\n",
       "                                                            tol=0.001,\n",
       "                                                            verbose=False),\n",
       "                                         learning_rate=1.0, loss='linear',\n",
       "                                         n_estimators=50, random_state=0),\n",
       "             iid='False', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.5, 1],\n",
       "                         'n_estimators': [50, 100, 200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': [50, 100, 200, 500],'learning_rate': [0.1,  0.5,   1]}\n",
    "ada_reg_svr = AdaBoostRegressor(SVR(C=100,gamma=0.001,kernel='linear'), random_state=0)\n",
    "\n",
    "grid_ada_svr = GridSearchCV(ada_reg_svr, params, cv=5, iid='False')\n",
    "grid_ada_svr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "AdaBoost Regressor with SVR\u001b[00m\n",
      "Best Params : {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Training Score  --> 0.9211399353196834\n",
      "Test Score      --> 0.8581108198426068\n"
     ]
    }
   ],
   "source": [
    "prRed(\"\\nAdaBoost Regressor with SVR\")\n",
    "print(\"Best Params :\", grid_ada_svr.best_params_)\n",
    "print(\"Training Score  -->\", grid_ada_svr.score(X_train,y_train))\n",
    "print(\"Test Score      -->\", grid_ada_svr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DT Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=0, subsample=1.0,\n",
       "                                                 tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='False', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.25, 0.5, 0.75, 1],\n",
       "                         'max_features': [2, 5, 10, 20],\n",
       "                         'n_estimators': [50, 100, 200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_features': [2,5,10,20] ,'n_estimators': [50, 100, 200, 500],'learning_rate': [0.1, 0.25, 0.5, 0.75, 1]}\n",
    "grad_gboost = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "grid_gboost = GridSearchCV(grad_gboost,params,cv=5,iid='False')\n",
    "grid_gboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "Gradient Boosting with DT Regressor\u001b[00m\n",
      "Best Params : {'learning_rate': 0.1, 'max_features': 10, 'n_estimators': 100}\n",
      "Training Score  --> 0.9553517920714709\n",
      "Test Score      --> 0.8867838592519329\n"
     ]
    }
   ],
   "source": [
    "prRed(\"\\nGradient Boosting with DT Regressor\")\n",
    "print(\"Best Params :\", grid_gboost.best_params_)\n",
    "print(\"Training Score  -->\", grid_gboost.score(X_train,y_train))\n",
    "print(\"Test Score      -->\", grid_gboost.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prinicipal Component Ananlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With 95% variance explained, Train and Test datasets were transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.95)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m \n",
      "Post PCA Transformation :\u001b[00m\n",
      "New dimension for the datasets is : 24\n"
     ]
    }
   ],
   "source": [
    "prRed(\"\\nPost PCA Transformation :\")\n",
    "print(\"New dimension for the datasets is :\",X_test_pca.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Models from Project 1 with PCA transformed 24 dimensions:\n",
    "-Taking only grid searched optimum parameters and re executing all the models below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age_08_04', 'Mfg_Month', 'Mfg_Year', 'KM', 'HP', 'Met_Color',\n",
       "       'Automatic', 'cc', 'Doors', 'Cylinders', 'Gears', 'Quarterly_Tax',\n",
       "       'Weight', 'Mfr_Guarantee', 'BOVAG_Guarantee', 'Guarantee_Period', 'ABS',\n",
       "       'Airbag_1', 'Airbag_2', 'Airco', 'Automatic_airco', 'Boardcomputer',\n",
       "       'CD_Player', 'Central_Lock', 'Powered_Windows', 'Power_Steering',\n",
       "       'Radio', 'Mistlamps', 'Sport_Model', 'Backseat_Divider', 'Metallic_Rim',\n",
       "       'Radio_cassette', 'Tow_Bar', 'Fuel_Type_CNG', 'Fuel_Type_Diesel',\n",
       "       'Fuel_Type_Petrol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_corolla.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Test Score --> 0.8332554899569575\n"
     ]
    }
   ],
   "source": [
    "lreg= LinearRegression()\n",
    "lreg.fit(X_train_pca,y_train)\n",
    "#lreg.fit(X_test_pca,y_test)\n",
    "lreg_train_score_pca=lreg.score(X_train_pca,y_train)\n",
    "lreg_test_score_pca=lreg.score(X_test_pca,y_test)\n",
    "print(\"Linear Test Score -->\", lreg_test_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Test Score --> 0.8339444787661593\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=5)\n",
    "lasso.fit(X_train_pca,y_train)\n",
    "lasso_train_score_pca = lasso.score(X_train_pca,y_train)\n",
    "lasso_test_score_pca = lasso.score(X_test_pca,y_test)\n",
    "print(\"Lasso Test Score -->\",lasso_test_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Test Score --> 0.8338818902061921\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 15)\n",
    "ridge.fit(X_train_pca,y_train)\n",
    "ridge_train_score_pca=ridge.score(X_train_pca,y_train)\n",
    "ridge_test_score_pca=ridge.score(X_test_pca,y_test)\n",
    "print(\"Ridge Test Score -->\",ridge_test_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Test Score --> 0.8332554899569575\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(1)\n",
    "poly.fit_transform(X_train_pca,y_train)\n",
    "poly_train_score_pca=lreg.score(X_train_pca,y_train)\n",
    "poly_test_score_pca=lreg.score(X_test_pca,y_test)\n",
    "print(\"Poly Test Score -->\",poly_test_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Test Score --> 0.8002188764797802\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train_pca,y_train)\n",
    "knn_train_score_pca=knn.score(X_train_pca,y_train)\n",
    "knn_test_score_pca=knn.score(X_test_pca,y_test)\n",
    "print(\"kNN Test Score -->\",knn_test_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVR Test Score --> 0.8321815987158626\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[10,50,100,150,200,250]}\n",
    "lsvr = GridSearchCV(LinearSVR(), param_grid, cv=5, iid='False')\n",
    "#print(lsvr.best_params_)\n",
    "lsvr.fit(X_train_pca,y_train)\n",
    "lsvr_train_score_pca=lsvr.score(X_train_pca,y_train)\n",
    "lsvr_test_score_pca=lsvr.score(X_test_pca,y_test)\n",
    "print(\"Linear SVR Test Score -->\",lsvr_test_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Test Score --> 0.8330682575646479\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(C=100,gamma=0.001,kernel='linear')\n",
    "\n",
    "svr.fit(X_train_pca,y_train)\n",
    "svr_train_score_pca=svr.score(X_train_pca,y_train)\n",
    "svr_test_score_pca=svr.score(X_test_pca,y_test)\n",
    "print(\"SVR Test Score -->\",svr_test_score_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_score_model =  [('Linear ', lreg_train_score_pca, lreg_test_score_pca),\n",
    "          ('Ridge ', ridge_train_score_pca, ridge_test_score_pca),\n",
    "          ('Lasso ', lasso_train_score_pca, lasso_test_score_pca),\n",
    "          ('Polynomial ', poly_train_score_pca, poly_test_score_pca),\n",
    "          ('kNN ', knn_train_score_pca, knn_test_score_pca),\n",
    "          ('LinearSVR ', lsvr_train_score_pca, lsvr_test_score_pca),\n",
    "\t\t  ('SVR ', svr_train_score_pca, svr_test_score_pca)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[91m With PCA\u001b[00m\n",
      "\n",
      "         Models  PCA Train_Score  PCA Test_Score\n",
      "0      Linear          0.907934        0.833255\n",
      "1       Ridge          0.907908        0.833882\n",
      "2       Lasso          0.907888        0.833944\n",
      "3  Polynomial          0.907934        0.833255\n",
      "4         kNN          0.897985        0.800219\n",
      "5   LinearSVR          0.904882        0.832182\n",
      "6         SVR          0.904971        0.833068\n"
     ]
    }
   ],
   "source": [
    "stat = pd.DataFrame(data = PCA_score_model, columns = ['Models', 'PCA Train_Score', 'PCA Test_Score'])\n",
    "prRed(\"With PCA\")\n",
    "print(\"\\n\",stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Without PCA Transformation\n",
    "             Models      Score_Train  Score_Test \n",
    "              Linear      0.922860    0.862248  \n",
    "               Ridge      0.922295    0.860712  \n",
    "               Lasso      0.922643    0.860758  \n",
    "          Polynomial      0.922859    0.862262  \n",
    "                 kNN      0.907167    0.818258  \n",
    "                 SVM      0.917875    0.845226 \n",
    "                 \n",
    "### <font color='red'> After PCA Transformation\n",
    "         Models  PCA Train_Score  PCA Test_Score\n",
    "        Linear          0.907934      0.833255\n",
    "         Ridge          0.907908      0.833882\n",
    "         Lasso          0.907888      0.833944\n",
    "    Polynomial          0.907934      0.833255\n",
    "           kNN          0.897985      0.800219\n",
    "     LinearSVR          0.904880      0.831845\n",
    "           SVR          0.904971      0.833068\n",
    "\n",
    " - Test scores of models post PCA transformation are ~3%(average) lower than test scores without PCA transformation, which is unusual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUERAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "rnn = Sequential()\n",
    "#Additon of input layer\n",
    "rnn.add(Dense(36,input_dim=36,kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "#Addition of hidden layer\n",
    "rnn.add(Dense(8,activation='relu',kernel_initializer='normal'))\n",
    "\n",
    "#Output layer\n",
    "rnn.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(loss='mse',optimizer='adam',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1077/1077 [==============================] - 0s 161us/step - loss: 129959798.9229 - mse: 129959792.0000\n",
      "Epoch 2/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 129928688.3565 - mse: 129928664.0000\n",
      "Epoch 3/500\n",
      "1077/1077 [==============================] - 0s 65us/step - loss: 129753258.6890 - mse: 129753264.0000\n",
      "Epoch 4/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 129208048.2006 - mse: 129208040.0000\n",
      "Epoch 5/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 128049103.0938 - mse: 128049080.0000\n",
      "Epoch 6/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 126082507.4243 - mse: 126082520.0000\n",
      "Epoch 7/500\n",
      "1077/1077 [==============================] - 0s 69us/step - loss: 123142512.2674 - mse: 123142528.0000\n",
      "Epoch 8/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 119121168.4308 - mse: 119121184.0000\n",
      "Epoch 9/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 114007488.3714 - mse: 114007464.0000\n",
      "Epoch 10/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 107887309.4373 - mse: 107887320.0000\n",
      "Epoch 11/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 100840532.4345 - mse: 100840528.0000\n",
      "Epoch 12/500\n",
      "1077/1077 [==============================] - 0s 62us/step - loss: 93166859.0975 - mse: 93166848.0000\n",
      "Epoch 13/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 85001697.5822 - mse: 85001672.0000\n",
      "Epoch 14/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 76773218.8004 - mse: 76773224.0000\n",
      "Epoch 15/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 68785920.2154 - mse: 68785912.0000\n",
      "Epoch 16/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 61348450.1207 - mse: 61348460.0000\n",
      "Epoch 17/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 54713817.4893 - mse: 54713812.0000\n",
      "Epoch 18/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 49024455.0344 - mse: 49024456.0000\n",
      "Epoch 19/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 44246837.6750 - mse: 44246836.0000\n",
      "Epoch 20/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 40342154.7372 - mse: 40342160.0000\n",
      "Epoch 21/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 37158515.4875 - mse: 37158516.0000\n",
      "Epoch 22/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 34485043.3723 - mse: 34485048.0000\n",
      "Epoch 23/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 32151013.7623 - mse: 32151018.0000\n",
      "Epoch 24/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 30051265.5673 - mse: 30051268.0000\n",
      "Epoch 25/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 28086514.3825 - mse: 28086516.0000\n",
      "Epoch 26/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 26222036.4215 - mse: 26222040.0000\n",
      "Epoch 27/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 24439995.9136 - mse: 24439998.0000\n",
      "Epoch 28/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 22714057.1606 - mse: 22714056.0000\n",
      "Epoch 29/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 21075320.2498 - mse: 21075322.0000\n",
      "Epoch 30/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 19513993.1253 - mse: 19513990.0000\n",
      "Epoch 31/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 18037616.0910 - mse: 18037616.0000\n",
      "Epoch 32/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 16651655.3584 - mse: 16651655.0000\n",
      "Epoch 33/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 15359856.6787 - mse: 15359857.0000\n",
      "Epoch 34/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 14172547.0009 - mse: 14172547.0000\n",
      "Epoch 35/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 13080667.8217 - mse: 13080670.0000\n",
      "Epoch 36/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 12098009.1690 - mse: 12098009.0000\n",
      "Epoch 37/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 11211933.5599 - mse: 11211936.0000\n",
      "Epoch 38/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 10424614.7864 - mse: 10424618.0000\n",
      "Epoch 39/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 9726664.1035 - mse: 9726664.0000\n",
      "Epoch 40/500\n",
      "1077/1077 [==============================] - 0s 63us/step - loss: 9112658.4991 - mse: 9112660.0000\n",
      "Epoch 41/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 8570197.9331 - mse: 8570197.0000\n",
      "Epoch 42/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 8102558.1365 - mse: 8102556.5000\n",
      "Epoch 43/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 7687578.9099 - mse: 7687580.0000\n",
      "Epoch 44/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 7331886.5747 - mse: 7331886.5000\n",
      "Epoch 45/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 7010045.1497 - mse: 7010044.0000\n",
      "Epoch 46/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 6727227.2929 - mse: 6727227.0000\n",
      "Epoch 47/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 6476528.7669 - mse: 6476528.0000\n",
      "Epoch 48/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 6245432.0135 - mse: 6245431.0000\n",
      "Epoch 49/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 6034632.8032 - mse: 6034633.5000\n",
      "Epoch 50/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 5845603.3770 - mse: 5845603.0000\n",
      "Epoch 51/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 5665382.3644 - mse: 5665382.0000\n",
      "Epoch 52/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 5499415.9763 - mse: 5499416.0000\n",
      "Epoch 53/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 5346553.6490 - mse: 5346552.5000\n",
      "Epoch 54/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 5204653.5734 - mse: 5204654.0000\n",
      "Epoch 55/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 5065777.5385 - mse: 5065778.0000\n",
      "Epoch 56/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 4938357.9805 - mse: 4938357.5000\n",
      "Epoch 57/500\n",
      "1077/1077 [==============================] - 0s 68us/step - loss: 4820641.1221 - mse: 4820641.5000\n",
      "Epoch 58/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 4701531.0497 - mse: 4701531.0000\n",
      "Epoch 59/500\n",
      "1077/1077 [==============================] - 0s 64us/step - loss: 4592414.5682 - mse: 4592413.5000\n",
      "Epoch 60/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 4487881.7885 - mse: 4487881.5000\n",
      "Epoch 61/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 4387693.7024 - mse: 4387694.0000\n",
      "Epoch 62/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 4289082.6226 - mse: 4289083.0000\n",
      "Epoch 63/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 4197643.7059 - mse: 4197644.0000\n",
      "Epoch 64/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 4109183.4461 - mse: 4109183.2500\n",
      "Epoch 65/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 4019192.1806 - mse: 4019192.0000\n",
      "Epoch 66/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 3937699.8359 - mse: 3937699.7500\n",
      "Epoch 67/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 3858306.0091 - mse: 3858306.5000\n",
      "Epoch 68/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 3781434.0713 - mse: 3781434.2500\n",
      "Epoch 69/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 3703707.0441 - mse: 3703707.5000\n",
      "Epoch 70/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 3630881.4735 - mse: 3630881.2500\n",
      "Epoch 71/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 3560408.8519 - mse: 3560408.7500\n",
      "Epoch 72/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 3491990.6416 - mse: 3491990.7500\n",
      "Epoch 73/500\n",
      "1077/1077 [==============================] - 0s 73us/step - loss: 3425314.6903 - mse: 3425315.2500\n",
      "Epoch 74/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 3358624.2256 - mse: 3358623.5000\n",
      "Epoch 75/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 3297508.8056 - mse: 3297508.7500\n",
      "Epoch 76/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 3235156.1762 - mse: 3235157.0000\n",
      "Epoch 77/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 3174894.3596 - mse: 3174894.7500\n",
      "Epoch 78/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 3117329.4420 - mse: 3117329.2500\n",
      "Epoch 79/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 3062475.8322 - mse: 3062475.7500\n",
      "Epoch 80/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 3006103.0409 - mse: 3006103.7500\n",
      "Epoch 81/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2951425.2362 - mse: 2951425.5000\n",
      "Epoch 82/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2899465.5550 - mse: 2899464.7500\n",
      "Epoch 83/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2848271.3883 - mse: 2848271.7500\n",
      "Epoch 84/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 2800031.1555 - mse: 2800031.2500\n",
      "Epoch 85/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 2749326.3979 - mse: 2749326.5000\n",
      "Epoch 86/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 2702570.2188 - mse: 2702570.2500\n",
      "Epoch 87/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 2657093.6554 - mse: 2657093.2500\n",
      "Epoch 88/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 2610626.4269 - mse: 2610626.5000\n",
      "Epoch 89/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 2565883.4431 - mse: 2565883.5000\n",
      "Epoch 90/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 2524096.6567 - mse: 2524096.7500\n",
      "Epoch 91/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 2483226.6418 - mse: 2483226.5000\n",
      "Epoch 92/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2440696.9308 - mse: 2440696.7500\n",
      "Epoch 93/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 2399346.0267 - mse: 2399346.2500\n",
      "Epoch 94/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 2360981.2647 - mse: 2360981.0000\n",
      "Epoch 95/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2320277.5149 - mse: 2320277.7500\n",
      "Epoch 96/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2285116.6071 - mse: 2285116.5000\n",
      "Epoch 97/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 2249194.6681 - mse: 2249194.5000\n",
      "Epoch 98/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 2209891.1435 - mse: 2209891.0000\n",
      "Epoch 99/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2176886.6105 - mse: 2176886.2500\n",
      "Epoch 100/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2144786.9920 - mse: 2144787.0000\n",
      "Epoch 101/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 2110396.0924 - mse: 2110396.2500\n",
      "Epoch 102/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 2079747.7549 - mse: 2079747.7500\n",
      "Epoch 103/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 2046674.9711 - mse: 2046674.6250\n",
      "Epoch 104/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 2016741.1685 - mse: 2016741.1250\n",
      "Epoch 105/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1989403.5684 - mse: 1989403.7500\n",
      "Epoch 106/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1960656.8107 - mse: 1960656.6250\n",
      "Epoch 107/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 1933011.2878 - mse: 1933011.3750\n",
      "Epoch 108/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1906025.3085 - mse: 1906025.1250\n",
      "Epoch 109/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1877789.2396 - mse: 1877789.2500\n",
      "Epoch 110/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1855458.6586 - mse: 1855458.7500\n",
      "Epoch 111/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1829670.5274 - mse: 1829670.5000\n",
      "Epoch 112/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1806455.4153 - mse: 1806455.2500\n",
      "Epoch 113/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1781777.5610 - mse: 1781777.3750\n",
      "Epoch 114/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1759825.9300 - mse: 1759826.1250\n",
      "Epoch 115/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 1741007.9869 - mse: 1741008.2500\n",
      "Epoch 116/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1718296.0053 - mse: 1718296.2500\n",
      "Epoch 117/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1695221.5364 - mse: 1695221.5000\n",
      "Epoch 118/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 1676349.4590 - mse: 1676349.5000\n",
      "Epoch 119/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1657805.6650 - mse: 1657805.5000\n",
      "Epoch 120/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1640978.6192 - mse: 1640978.6250\n",
      "Epoch 121/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1622092.1997 - mse: 1622092.1250\n",
      "Epoch 122/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1602977.3513 - mse: 1602977.6250\n",
      "Epoch 123/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1588577.4652 - mse: 1588577.6250\n",
      "Epoch 124/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 1570591.0369 - mse: 1570591.1250\n",
      "Epoch 125/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1554792.0649 - mse: 1554792.3750\n",
      "Epoch 126/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1541638.1249 - mse: 1541638.2500\n",
      "Epoch 127/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1524976.3952 - mse: 1524976.3750\n",
      "Epoch 128/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1509714.6527 - mse: 1509714.8750\n",
      "Epoch 129/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1495539.2314 - mse: 1495539.3750\n",
      "Epoch 130/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 1481473.0389 - mse: 1481473.0000\n",
      "Epoch 131/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1466037.1360 - mse: 1466037.0000\n",
      "Epoch 132/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1454275.8460 - mse: 1454275.6250\n",
      "Epoch 133/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 1440852.3005 - mse: 1440852.3750\n",
      "Epoch 134/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1428851.6424 - mse: 1428851.8750\n",
      "Epoch 135/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1415640.3238 - mse: 1415640.2500\n",
      "Epoch 136/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1403410.6068 - mse: 1403410.7500\n",
      "Epoch 137/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 1393966.2299 - mse: 1393966.0000\n",
      "Epoch 138/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1379351.7786 - mse: 1379351.8750\n",
      "Epoch 139/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1370078.4744 - mse: 1370078.1250\n",
      "Epoch 140/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 1358841.4503 - mse: 1358841.5000\n",
      "Epoch 141/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 1348479.3346 - mse: 1348479.2500\n",
      "Epoch 142/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 1339229.8893 - mse: 1339229.7500\n",
      "Epoch 143/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1326976.0552 - mse: 1326976.2500\n",
      "Epoch 144/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 1318653.2686 - mse: 1318653.2500\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077/1077 [==============================] - 0s 51us/step - loss: 1307964.4801 - mse: 1307964.3750\n",
      "Epoch 146/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1296331.3058 - mse: 1296331.3750\n",
      "Epoch 147/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 1289107.5014 - mse: 1289107.2500\n",
      "Epoch 148/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 1278882.4776 - mse: 1278882.6250\n",
      "Epoch 149/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1270457.9271 - mse: 1270457.5000\n",
      "Epoch 150/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1261769.4240 - mse: 1261769.6250\n",
      "Epoch 151/500\n",
      "1077/1077 [==============================] - ETA: 0s - loss: 1193427.7500 - mse: 1193427.750 - 0s 50us/step - loss: 1254681.9615 - mse: 1254681.8750\n",
      "Epoch 152/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1246175.8092 - mse: 1246175.6250\n",
      "Epoch 153/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1237263.3659 - mse: 1237263.6250\n",
      "Epoch 154/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1231242.4929 - mse: 1231242.5000\n",
      "Epoch 155/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1221506.4877 - mse: 1221506.6250\n",
      "Epoch 156/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1216476.7250 - mse: 1216476.7500\n",
      "Epoch 157/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1209789.8897 - mse: 1209790.0000\n",
      "Epoch 158/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 1200066.8981 - mse: 1200066.6250\n",
      "Epoch 159/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1196211.2419 - mse: 1196211.2500\n",
      "Epoch 160/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1189395.6504 - mse: 1189395.7500\n",
      "Epoch 161/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1180381.4092 - mse: 1180381.2500\n",
      "Epoch 162/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 1175197.4878 - mse: 1175197.3750\n",
      "Epoch 163/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1167585.7437 - mse: 1167585.6250\n",
      "Epoch 164/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1163969.3441 - mse: 1163969.3750\n",
      "Epoch 165/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1158172.8857 - mse: 1158172.6250\n",
      "Epoch 166/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1152113.5241 - mse: 1152113.5000\n",
      "Epoch 167/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1146622.7378 - mse: 1146622.7500\n",
      "Epoch 168/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1141198.7460 - mse: 1141198.7500\n",
      "Epoch 169/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 1135868.8140 - mse: 1135868.7500\n",
      "Epoch 170/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1131517.9568 - mse: 1131517.7500\n",
      "Epoch 171/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 1127514.1602 - mse: 1127514.2500\n",
      "Epoch 172/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1121485.0390 - mse: 1121485.1250\n",
      "Epoch 173/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1115402.6819 - mse: 1115402.6250\n",
      "Epoch 174/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1111374.0945 - mse: 1111374.3750\n",
      "Epoch 175/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 1107100.0229 - mse: 1107100.0000\n",
      "Epoch 176/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 1101884.2055 - mse: 1101884.2500\n",
      "Epoch 177/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1097978.9752 - mse: 1097979.1250\n",
      "Epoch 178/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 1096513.6786 - mse: 1096513.7500\n",
      "Epoch 179/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1089088.8404 - mse: 1089088.7500\n",
      "Epoch 180/500\n",
      "1077/1077 [==============================] - ETA: 0s - loss: 1062443.2999 - mse: 1062443.125 - 0s 54us/step - loss: 1084448.4824 - mse: 1084448.2500\n",
      "Epoch 181/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1081635.5180 - mse: 1081635.5000\n",
      "Epoch 182/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1075087.8953 - mse: 1075087.7500\n",
      "Epoch 183/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1072272.9377 - mse: 1072272.8750\n",
      "Epoch 184/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1071210.3373 - mse: 1071210.5000\n",
      "Epoch 185/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1064784.3114 - mse: 1064784.2500\n",
      "Epoch 186/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1060796.2181 - mse: 1060796.1250\n",
      "Epoch 187/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1057673.1415 - mse: 1057672.8750\n",
      "Epoch 188/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1054729.7492 - mse: 1054729.8750\n",
      "Epoch 189/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1049201.3213 - mse: 1049201.5000\n",
      "Epoch 190/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1047823.9449 - mse: 1047824.3125\n",
      "Epoch 191/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1042598.6049 - mse: 1042598.5000\n",
      "Epoch 192/500\n",
      "1077/1077 [==============================] - 0s 60us/step - loss: 1039537.2213 - mse: 1039537.0625\n",
      "Epoch 193/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1037241.0327 - mse: 1037241.1875\n",
      "Epoch 194/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1033990.1729 - mse: 1033990.3125\n",
      "Epoch 195/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1031989.8792 - mse: 1031989.8125\n",
      "Epoch 196/500\n",
      "1077/1077 [==============================] - ETA: 0s - loss: 1022391.8029 - mse: 1022391.937 - 0s 53us/step - loss: 1026655.0713 - mse: 1026655.1875\n",
      "Epoch 197/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 1022280.2047 - mse: 1022280.1250\n",
      "Epoch 198/500\n",
      "1077/1077 [==============================] - 0s 65us/step - loss: 1019852.5402 - mse: 1019852.5625\n",
      "Epoch 199/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 1017498.2028 - mse: 1017498.1250\n",
      "Epoch 200/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 1012818.3221 - mse: 1012818.2500\n",
      "Epoch 201/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1009922.3463 - mse: 1009922.3750\n",
      "Epoch 202/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 1009795.4625 - mse: 1009795.4375\n",
      "Epoch 203/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 1004340.0479 - mse: 1004339.8125\n",
      "Epoch 204/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 1002081.2870 - mse: 1002081.4375\n",
      "Epoch 205/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 999431.6438 - mse: 999431.7500\n",
      "Epoch 206/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 994703.3488 - mse: 994703.3750\n",
      "Epoch 207/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 993060.5435 - mse: 993060.7500\n",
      "Epoch 208/500\n",
      "1077/1077 [==============================] - 0s 62us/step - loss: 992750.6737 - mse: 992750.8750\n",
      "Epoch 209/500\n",
      "1077/1077 [==============================] - 0s 75us/step - loss: 987593.1024 - mse: 987593.1875\n",
      "Epoch 210/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 985562.0946 - mse: 985562.1250\n",
      "Epoch 211/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 981279.0220 - mse: 981278.8750\n",
      "Epoch 212/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 979116.0398 - mse: 979115.9375\n",
      "Epoch 213/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 977955.4973 - mse: 977955.6250\n",
      "Epoch 214/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 975350.3185 - mse: 975350.3125\n",
      "Epoch 215/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 973776.7621 - mse: 973776.6250\n",
      "Epoch 216/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 970144.7441 - mse: 970144.8125\n",
      "Epoch 217/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 969202.0182 - mse: 969202.0625\n",
      "Epoch 218/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 965967.5592 - mse: 965967.3750\n",
      "Epoch 219/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 963160.6078 - mse: 963160.6250\n",
      "Epoch 220/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 962070.3087 - mse: 962070.3125\n",
      "Epoch 221/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 960848.8563 - mse: 960848.9375\n",
      "Epoch 222/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 954712.6048 - mse: 954712.6875\n",
      "Epoch 223/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 956171.8597 - mse: 956171.8750\n",
      "Epoch 224/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 950627.7191 - mse: 950627.8750\n",
      "Epoch 225/500\n",
      "1077/1077 [==============================] - 0s 70us/step - loss: 951463.7663 - mse: 951463.8125\n",
      "Epoch 226/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 948597.0963 - mse: 948597.2500\n",
      "Epoch 227/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 944827.8041 - mse: 944827.8750\n",
      "Epoch 228/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 942990.6657 - mse: 942990.6250\n",
      "Epoch 229/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 939049.0695 - mse: 939049.0000\n",
      "Epoch 230/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 937469.1471 - mse: 937469.1250\n",
      "Epoch 231/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 936497.7096 - mse: 936497.6875\n",
      "Epoch 232/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 933093.5580 - mse: 933093.5000\n",
      "Epoch 233/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 931298.9282 - mse: 931298.8750\n",
      "Epoch 234/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 929031.8190 - mse: 929031.7500\n",
      "Epoch 235/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 925810.7827 - mse: 925810.7500\n",
      "Epoch 236/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 924763.5169 - mse: 924763.5000\n",
      "Epoch 237/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 922663.2897 - mse: 922663.2500\n",
      "Epoch 238/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 922894.9188 - mse: 922895.0625\n",
      "Epoch 239/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 917909.0656 - mse: 917909.0625\n",
      "Epoch 240/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 914694.2051 - mse: 914694.1250\n",
      "Epoch 241/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 917060.0555 - mse: 917060.1875\n",
      "Epoch 242/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 913071.1611 - mse: 913071.1250\n",
      "Epoch 243/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 909519.5613 - mse: 909519.6875\n",
      "Epoch 244/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 907714.3427 - mse: 907714.3750\n",
      "Epoch 245/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 907283.1310 - mse: 907283.0625\n",
      "Epoch 246/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 903183.7732 - mse: 903183.7500\n",
      "Epoch 247/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 903975.6888 - mse: 903975.7500\n",
      "Epoch 248/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 898469.5427 - mse: 898469.6875\n",
      "Epoch 249/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 896738.5338 - mse: 896738.4375\n",
      "Epoch 250/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 896233.5805 - mse: 896233.6875\n",
      "Epoch 251/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 893679.4413 - mse: 893679.5625\n",
      "Epoch 252/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 891627.7461 - mse: 891627.5625\n",
      "Epoch 253/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 891502.4620 - mse: 891502.6250\n",
      "Epoch 254/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 888376.9988 - mse: 888377.0625\n",
      "Epoch 255/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 887721.7062 - mse: 887721.5625\n",
      "Epoch 256/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 886611.2632 - mse: 886611.1250\n",
      "Epoch 257/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 885893.1573 - mse: 885893.2500\n",
      "Epoch 258/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 880842.7734 - mse: 880842.6250\n",
      "Epoch 259/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 879515.6019 - mse: 879515.5625\n",
      "Epoch 260/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 879522.6158 - mse: 879522.6250\n",
      "Epoch 261/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 877237.6359 - mse: 877237.5000\n",
      "Epoch 262/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 873843.8618 - mse: 873844.0000\n",
      "Epoch 263/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 873847.8996 - mse: 873847.8125\n",
      "Epoch 264/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 870655.0870 - mse: 870654.9375\n",
      "Epoch 265/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 869819.5675 - mse: 869819.6875\n",
      "Epoch 266/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 867359.6550 - mse: 867359.6250\n",
      "Epoch 267/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 865338.9590 - mse: 865338.9375\n",
      "Epoch 268/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 865085.6812 - mse: 865085.5625\n",
      "Epoch 269/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 862237.9590 - mse: 862237.9375\n",
      "Epoch 270/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 862190.1508 - mse: 862190.1875\n",
      "Epoch 271/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 860795.3793 - mse: 860795.2500\n",
      "Epoch 272/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 858795.9901 - mse: 858795.8125\n",
      "Epoch 273/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 857745.7844 - mse: 857745.8125\n",
      "Epoch 274/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 855070.3032 - mse: 855070.4375\n",
      "Epoch 275/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 853322.0721 - mse: 853322.1250\n",
      "Epoch 276/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 852702.5302 - mse: 852702.5625\n",
      "Epoch 277/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 851745.1762 - mse: 851745.1875\n",
      "Epoch 278/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 850429.2906 - mse: 850429.2500\n",
      "Epoch 279/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 847569.8845 - mse: 847570.0000\n",
      "Epoch 280/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 848857.4793 - mse: 848857.5000\n",
      "Epoch 281/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 843987.2097 - mse: 843987.2500\n",
      "Epoch 282/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 844229.0624 - mse: 844229.0625\n",
      "Epoch 283/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 840665.8992 - mse: 840666.0000\n",
      "Epoch 284/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 841083.4784 - mse: 841083.5000\n",
      "Epoch 285/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 838299.0720 - mse: 838299.0625\n",
      "Epoch 286/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 836923.0504 - mse: 836923.1250\n",
      "Epoch 287/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 836537.1594 - mse: 836537.0625\n",
      "Epoch 288/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 834364.0236 - mse: 834364.0625\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077/1077 [==============================] - 0s 54us/step - loss: 836054.3715 - mse: 836054.3125\n",
      "Epoch 290/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 831709.5763 - mse: 831709.6250\n",
      "Epoch 291/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 831637.7170 - mse: 831637.7500\n",
      "Epoch 292/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 828573.7129 - mse: 828573.8125: 0s - loss: 812285.6250 - mse: 812285.812\n",
      "Epoch 293/500\n",
      "1077/1077 [==============================] - 0s 64us/step - loss: 827147.1552 - mse: 827147.2500\n",
      "Epoch 294/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 825304.2516 - mse: 825304.3750\n",
      "Epoch 295/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 825175.8125 - mse: 825175.8750\n",
      "Epoch 296/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 823206.7013 - mse: 823206.7500\n",
      "Epoch 297/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 823211.9884 - mse: 823212.0625\n",
      "Epoch 298/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 823896.3183 - mse: 823896.3750\n",
      "Epoch 299/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 819920.1508 - mse: 819920.2500\n",
      "Epoch 300/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 817999.0331 - mse: 817999.1250\n",
      "Epoch 301/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 817532.7812 - mse: 817532.9375\n",
      "Epoch 302/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 816655.2920 - mse: 816655.3750\n",
      "Epoch 303/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 815103.6849 - mse: 815103.8125\n",
      "Epoch 304/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 816762.4152 - mse: 816762.5625\n",
      "Epoch 305/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 812318.7780 - mse: 812318.7500\n",
      "Epoch 306/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 812469.6376 - mse: 812469.6250\n",
      "Epoch 307/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 810350.0323 - mse: 810350.0000\n",
      "Epoch 308/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 810809.0318 - mse: 810809.1250\n",
      "Epoch 309/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 807680.4442 - mse: 807680.5000\n",
      "Epoch 310/500\n",
      "1077/1077 [==============================] - 0s 61us/step - loss: 806600.2223 - mse: 806600.2500\n",
      "Epoch 311/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 806166.9673 - mse: 806167.0000\n",
      "Epoch 312/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 806210.8331 - mse: 806210.8125\n",
      "Epoch 313/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 803913.5449 - mse: 803913.6250\n",
      "Epoch 314/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 804182.3951 - mse: 804182.4375\n",
      "Epoch 315/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 802283.3974 - mse: 802283.3750\n",
      "Epoch 316/500\n",
      "1077/1077 [==============================] - 0s 68us/step - loss: 800798.1799 - mse: 800798.0625\n",
      "Epoch 317/500\n",
      "1077/1077 [==============================] - 0s 60us/step - loss: 799915.6558 - mse: 799915.6250\n",
      "Epoch 318/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 798480.9988 - mse: 798480.9375\n",
      "Epoch 319/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 800461.3163 - mse: 800461.1250\n",
      "Epoch 320/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 797090.5500 - mse: 797090.5625\n",
      "Epoch 321/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 797063.7545 - mse: 797063.7500\n",
      "Epoch 322/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 797737.2134 - mse: 797737.1250\n",
      "Epoch 323/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 794982.1878 - mse: 794982.0625\n",
      "Epoch 324/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 792370.2444 - mse: 792370.2500\n",
      "Epoch 325/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 792397.8592 - mse: 792397.8750\n",
      "Epoch 326/500\n",
      "1077/1077 [==============================] - 0s 63us/step - loss: 793445.6136 - mse: 793445.6250\n",
      "Epoch 327/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 791056.4807 - mse: 791056.5000\n",
      "Epoch 328/500\n",
      "1077/1077 [==============================] - 0s 72us/step - loss: 788649.0149 - mse: 788649.1250\n",
      "Epoch 329/500\n",
      "1077/1077 [==============================] - 0s 84us/step - loss: 787171.0548 - mse: 787171.1250\n",
      "Epoch 330/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 786896.5451 - mse: 786896.5000\n",
      "Epoch 331/500\n",
      "1077/1077 [==============================] - 0s 65us/step - loss: 785082.3912 - mse: 785082.1875\n",
      "Epoch 332/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 784062.6164 - mse: 784062.6875\n",
      "Epoch 333/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 784212.6141 - mse: 784212.6875\n",
      "Epoch 334/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 782964.1716 - mse: 782964.3125\n",
      "Epoch 335/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 780809.8202 - mse: 780809.8750\n",
      "Epoch 336/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 780423.1217 - mse: 780423.0625\n",
      "Epoch 337/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 781364.8128 - mse: 781364.6875\n",
      "Epoch 338/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 780205.7108 - mse: 780205.7500\n",
      "Epoch 339/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 779437.7735 - mse: 779437.7500\n",
      "Epoch 340/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 777760.5327 - mse: 777760.5625\n",
      "Epoch 341/500\n",
      "1077/1077 [==============================] - 0s 63us/step - loss: 777125.4047 - mse: 777125.3125\n",
      "Epoch 342/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 775329.8829 - mse: 775329.7500\n",
      "Epoch 343/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 775976.0010 - mse: 775976.0000\n",
      "Epoch 344/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 774126.0490 - mse: 774125.9375\n",
      "Epoch 345/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 774653.3330 - mse: 774653.3125\n",
      "Epoch 346/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 773964.3287 - mse: 773964.3750\n",
      "Epoch 347/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 772535.2521 - mse: 772535.1875\n",
      "Epoch 348/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 770061.2540 - mse: 770061.3125\n",
      "Epoch 349/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 769361.1017 - mse: 769361.0625\n",
      "Epoch 350/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 769087.0433 - mse: 769087.0625\n",
      "Epoch 351/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 768620.8375 - mse: 768620.8750\n",
      "Epoch 352/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 769217.3536 - mse: 769217.1875\n",
      "Epoch 353/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 767121.5102 - mse: 767121.5000\n",
      "Epoch 354/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 766197.5500 - mse: 766197.4375\n",
      "Epoch 355/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 766364.5630 - mse: 766364.5625\n",
      "Epoch 356/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 767035.5532 - mse: 767035.3750\n",
      "Epoch 357/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 765236.4246 - mse: 765236.3125\n",
      "Epoch 358/500\n",
      "1077/1077 [==============================] - 0s 67us/step - loss: 763396.0055 - mse: 763396.1250\n",
      "Epoch 359/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 763053.0624 - mse: 763053.0625\n",
      "Epoch 360/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 763228.9412 - mse: 763229.0000\n",
      "Epoch 361/500\n",
      "1077/1077 [==============================] - 0s 62us/step - loss: 762472.4755 - mse: 762472.4375\n",
      "Epoch 362/500\n",
      "1077/1077 [==============================] - 0s 75us/step - loss: 761998.0312 - mse: 761997.9375\n",
      "Epoch 363/500\n",
      "1077/1077 [==============================] - 0s 75us/step - loss: 759834.6926 - mse: 759834.6875\n",
      "Epoch 364/500\n",
      "1077/1077 [==============================] - 0s 80us/step - loss: 758880.0529 - mse: 758880.0000\n",
      "Epoch 365/500\n",
      "1077/1077 [==============================] - 0s 69us/step - loss: 756994.6297 - mse: 756994.6250\n",
      "Epoch 366/500\n",
      "1077/1077 [==============================] - 0s 64us/step - loss: 761040.8780 - mse: 761040.8125\n",
      "Epoch 367/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 756079.2804 - mse: 756079.1250\n",
      "Epoch 368/500\n",
      "1077/1077 [==============================] - 0s 61us/step - loss: 756001.3647 - mse: 756001.3125\n",
      "Epoch 369/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 754473.1100 - mse: 754473.1875\n",
      "Epoch 370/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 756233.6898 - mse: 756233.6875\n",
      "Epoch 371/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 753927.3697 - mse: 753927.4375\n",
      "Epoch 372/500\n",
      "1077/1077 [==============================] - 0s 60us/step - loss: 752977.1856 - mse: 752977.2500\n",
      "Epoch 373/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 753931.7625 - mse: 753931.8125\n",
      "Epoch 374/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 749594.9025 - mse: 749594.8750\n",
      "Epoch 375/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 750398.3144 - mse: 750398.2500\n",
      "Epoch 376/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 749601.1455 - mse: 749601.1875\n",
      "Epoch 377/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 748307.8737 - mse: 748307.7500\n",
      "Epoch 378/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 748885.6757 - mse: 748885.6875\n",
      "Epoch 379/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 748701.6660 - mse: 748701.6250\n",
      "Epoch 380/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 747071.3885 - mse: 747071.3125\n",
      "Epoch 381/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 745445.0512 - mse: 745445.1875\n",
      "Epoch 382/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 745488.8921 - mse: 745489.0000\n",
      "Epoch 383/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 745588.5068 - mse: 745588.5000\n",
      "Epoch 384/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 745390.2309 - mse: 745390.3750\n",
      "Epoch 385/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 743304.6175 - mse: 743304.5625\n",
      "Epoch 386/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 743843.6883 - mse: 743843.6250\n",
      "Epoch 387/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 742004.8563 - mse: 742004.8125\n",
      "Epoch 388/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 741104.6755 - mse: 741104.6875\n",
      "Epoch 389/500\n",
      "1077/1077 [==============================] - ETA: 0s - loss: 767871.5734 - mse: 767871.500 - 0s 62us/step - loss: 740880.7017 - mse: 740880.5625\n",
      "Epoch 390/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 740869.2537 - mse: 740869.2500\n",
      "Epoch 391/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 740986.4572 - mse: 740986.5625\n",
      "Epoch 392/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 739576.3471 - mse: 739576.2500\n",
      "Epoch 393/500\n",
      "1077/1077 [==============================] - 0s 68us/step - loss: 738920.1873 - mse: 738920.1250\n",
      "Epoch 394/500\n",
      "1077/1077 [==============================] - 0s 64us/step - loss: 739059.0687 - mse: 739059.1250\n",
      "Epoch 395/500\n",
      "1077/1077 [==============================] - 0s 57us/step - loss: 737378.7108 - mse: 737378.6875\n",
      "Epoch 396/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 736604.2250 - mse: 736604.3750\n",
      "Epoch 397/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 736489.6915 - mse: 736489.6875\n",
      "Epoch 398/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 735662.7597 - mse: 735662.8125\n",
      "Epoch 399/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 735040.7056 - mse: 735040.7500\n",
      "Epoch 400/500\n",
      "1077/1077 [==============================] - 0s 61us/step - loss: 734569.3277 - mse: 734569.3125\n",
      "Epoch 401/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 733400.8091 - mse: 733400.7500\n",
      "Epoch 402/500\n",
      "1077/1077 [==============================] - 0s 60us/step - loss: 733182.7231 - mse: 733182.8125\n",
      "Epoch 403/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 732272.1539 - mse: 732272.1875\n",
      "Epoch 404/500\n",
      "1077/1077 [==============================] - 0s 62us/step - loss: 731671.5280 - mse: 731671.5625\n",
      "Epoch 405/500\n",
      "1077/1077 [==============================] - 0s 60us/step - loss: 731363.3925 - mse: 731363.5000\n",
      "Epoch 406/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 730348.7786 - mse: 730348.7500\n",
      "Epoch 407/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 733058.3693 - mse: 733058.5000\n",
      "Epoch 408/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 730294.9778 - mse: 730295.0000\n",
      "Epoch 409/500\n",
      "1077/1077 [==============================] - 0s 56us/step - loss: 728842.7126 - mse: 728842.7500\n",
      "Epoch 410/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 728137.3025 - mse: 728137.3125\n",
      "Epoch 411/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 726477.3667 - mse: 726477.1875\n",
      "Epoch 412/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 727047.8144 - mse: 727047.8125\n",
      "Epoch 413/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 726189.2977 - mse: 726189.2500\n",
      "Epoch 414/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 726225.0988 - mse: 726225.1250\n",
      "Epoch 415/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 725255.8387 - mse: 725255.8125\n",
      "Epoch 416/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 724578.2319 - mse: 724578.1875\n",
      "Epoch 417/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 725354.5950 - mse: 725354.7500\n",
      "Epoch 418/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 724037.4475 - mse: 724037.4375\n",
      "Epoch 419/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 723092.2662 - mse: 723092.3125\n",
      "Epoch 420/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 722978.3492 - mse: 722978.3750\n",
      "Epoch 421/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 722066.2535 - mse: 722066.3125\n",
      "Epoch 422/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 721887.2465 - mse: 721887.2500\n",
      "Epoch 423/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 720544.4235 - mse: 720544.3750\n",
      "Epoch 424/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 720521.5743 - mse: 720521.6250\n",
      "Epoch 425/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 723580.5337 - mse: 723580.5625\n",
      "Epoch 426/500\n",
      "1077/1077 [==============================] - 0s 66us/step - loss: 720873.1534 - mse: 720873.1875\n",
      "Epoch 427/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 718567.0113 - mse: 718566.9375\n",
      "Epoch 428/500\n",
      "1077/1077 [==============================] - 0s 63us/step - loss: 717600.5982 - mse: 717600.5000\n",
      "Epoch 429/500\n",
      "1077/1077 [==============================] - 0s 61us/step - loss: 718624.5340 - mse: 718624.5625\n",
      "Epoch 430/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 716382.3285 - mse: 716382.3125\n",
      "Epoch 431/500\n",
      "1077/1077 [==============================] - 0s 72us/step - loss: 718049.8770 - mse: 718049.9375\n",
      "Epoch 432/500\n",
      "1077/1077 [==============================] - 0s 70us/step - loss: 718070.9560 - mse: 718070.9375\n",
      "Epoch 433/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 716349.1200 - mse: 716349.0625\n",
      "Epoch 434/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 715208.8786 - mse: 715208.9375\n",
      "Epoch 435/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077/1077 [==============================] - 0s 52us/step - loss: 715813.5263 - mse: 715813.5625\n",
      "Epoch 436/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 714895.1681 - mse: 714895.2500\n",
      "Epoch 437/500\n",
      "1077/1077 [==============================] - 0s 77us/step - loss: 713538.1630 - mse: 713538.0000\n",
      "Epoch 438/500\n",
      "1077/1077 [==============================] - 0s 84us/step - loss: 713207.5381 - mse: 713207.5625\n",
      "Epoch 439/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 713619.6438 - mse: 713619.6250\n",
      "Epoch 440/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 712752.8212 - mse: 712752.7500\n",
      "Epoch 441/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 710869.0070 - mse: 710868.9375\n",
      "Epoch 442/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 710349.0038 - mse: 710349.0000\n",
      "Epoch 443/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 711198.6260 - mse: 711198.5000\n",
      "Epoch 444/500\n",
      "1077/1077 [==============================] - 0s 67us/step - loss: 709674.9916 - mse: 709674.9375\n",
      "Epoch 445/500\n",
      "1077/1077 [==============================] - 0s 73us/step - loss: 708957.3271 - mse: 708957.3125\n",
      "Epoch 446/500\n",
      "1077/1077 [==============================] - 0s 61us/step - loss: 709269.2054 - mse: 709269.1875\n",
      "Epoch 447/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 709496.5217 - mse: 709496.5625\n",
      "Epoch 448/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 707609.3089 - mse: 707609.2500\n",
      "Epoch 449/500\n",
      "1077/1077 [==============================] - 0s 66us/step - loss: 707662.1991 - mse: 707662.1875\n",
      "Epoch 450/500\n",
      "1077/1077 [==============================] - 0s 73us/step - loss: 707312.9589 - mse: 707312.9375\n",
      "Epoch 451/500\n",
      "1077/1077 [==============================] - 0s 62us/step - loss: 705784.1728 - mse: 705784.1875\n",
      "Epoch 452/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 707365.9870 - mse: 707366.0000\n",
      "Epoch 453/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 705593.7593 - mse: 705593.6875: 0s - loss: 713432.8648 - mse: 713432.812\n",
      "Epoch 454/500\n",
      "1077/1077 [==============================] - 0s 47us/step - loss: 705256.4766 - mse: 705256.4375\n",
      "Epoch 455/500\n",
      "1077/1077 [==============================] - 0s 62us/step - loss: 704428.0574 - mse: 704428.0625\n",
      "Epoch 456/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 705006.6617 - mse: 705006.6875\n",
      "Epoch 457/500\n",
      "1077/1077 [==============================] - 0s 61us/step - loss: 702249.8278 - mse: 702249.8125\n",
      "Epoch 458/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 702219.5862 - mse: 702219.5625\n",
      "Epoch 459/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 704098.5463 - mse: 704098.6250\n",
      "Epoch 460/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 703125.5515 - mse: 703125.4375\n",
      "Epoch 461/500\n",
      "1077/1077 [==============================] - 0s 50us/step - loss: 699989.9497 - mse: 699989.9375\n",
      "Epoch 462/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 700291.3011 - mse: 700291.3750\n",
      "Epoch 463/500\n",
      "1077/1077 [==============================] - 0s 70us/step - loss: 698934.8872 - mse: 698935.0000\n",
      "Epoch 464/500\n",
      "1077/1077 [==============================] - 0s 70us/step - loss: 699851.5325 - mse: 699851.5000\n",
      "Epoch 465/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 701796.1727 - mse: 701796.1875\n",
      "Epoch 466/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 697903.8799 - mse: 697903.8125\n",
      "Epoch 467/500\n",
      "1077/1077 [==============================] - 0s 59us/step - loss: 697256.1511 - mse: 697256.1875\n",
      "Epoch 468/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 698281.9868 - mse: 698282.0625\n",
      "Epoch 469/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 699076.3660 - mse: 699076.2500\n",
      "Epoch 470/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 697057.8876 - mse: 697058.0000\n",
      "Epoch 471/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 696453.0987 - mse: 696453.2500\n",
      "Epoch 472/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 695324.3184 - mse: 695324.3750\n",
      "Epoch 473/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 696608.1423 - mse: 696608.1875\n",
      "Epoch 474/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 695852.6587 - mse: 695852.5625\n",
      "Epoch 475/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 693775.1516 - mse: 693775.1250\n",
      "Epoch 476/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 694440.1519 - mse: 694440.1875\n",
      "Epoch 477/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 694059.3517 - mse: 694059.3750\n",
      "Epoch 478/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 692301.3299 - mse: 692301.3750\n",
      "Epoch 479/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 694194.7552 - mse: 694194.8125\n",
      "Epoch 480/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 693087.7238 - mse: 693087.8125\n",
      "Epoch 481/500\n",
      "1077/1077 [==============================] - 0s 48us/step - loss: 693666.1284 - mse: 693666.1250\n",
      "Epoch 482/500\n",
      "1077/1077 [==============================] - 0s 54us/step - loss: 690503.9058 - mse: 690503.9375\n",
      "Epoch 483/500\n",
      "1077/1077 [==============================] - 0s 65us/step - loss: 690538.4308 - mse: 690538.4375\n",
      "Epoch 484/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 690691.4906 - mse: 690691.5625\n",
      "Epoch 485/500\n",
      "1077/1077 [==============================] - 0s 68us/step - loss: 690988.9465 - mse: 690988.8750\n",
      "Epoch 486/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 690618.3419 - mse: 690618.3125\n",
      "Epoch 487/500\n",
      "1077/1077 [==============================] - 0s 52us/step - loss: 689798.2437 - mse: 689798.3125\n",
      "Epoch 488/500\n",
      "1077/1077 [==============================] - ETA: 0s - loss: 689930.2081 - mse: 689930.1875  - 0s 56us/step - loss: 688747.5272 - mse: 688747.5000\n",
      "Epoch 489/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 689417.9356 - mse: 689417.8750\n",
      "Epoch 490/500\n",
      "1077/1077 [==============================] - 0s 55us/step - loss: 687382.1878 - mse: 687382.2500\n",
      "Epoch 491/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 686046.1962 - mse: 686046.1250\n",
      "Epoch 492/500\n",
      "1077/1077 [==============================] - 0s 51us/step - loss: 685803.5992 - mse: 685803.6875\n",
      "Epoch 493/500\n",
      "1077/1077 [==============================] - 0s 65us/step - loss: 686372.3296 - mse: 686372.3750\n",
      "Epoch 494/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 685457.2388 - mse: 685457.2500\n",
      "Epoch 495/500\n",
      "1077/1077 [==============================] - 0s 53us/step - loss: 687420.1699 - mse: 687420.1875\n",
      "Epoch 496/500\n",
      "1077/1077 [==============================] - 0s 58us/step - loss: 686851.5276 - mse: 686851.6250\n",
      "Epoch 497/500\n",
      "1077/1077 [==============================] - 0s 71us/step - loss: 687261.4749 - mse: 687261.5000\n",
      "Epoch 498/500\n",
      "1077/1077 [==============================] - 0s 74us/step - loss: 684088.6572 - mse: 684088.6250\n",
      "Epoch 499/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 683882.6454 - mse: 683882.5625\n",
      "Epoch 500/500\n",
      "1077/1077 [==============================] - 0s 49us/step - loss: 684349.3043 - mse: 684349.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2561cec0a88>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(X_train,y_train,epochs=500, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 70us/step\n",
      "\u001b[1m \u001b[91m \n",
      "RNN Scores :\u001b[00m\n",
      "Train Score --> 0.948001308610764\n",
      "Test Score  --> 0.8661763993633015\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "rnn.evaluate(X_test,y_test)\n",
    "\n",
    "y_train_pred = rnn.predict(X_train)\n",
    "y_test_pred = rnn.predict(X_test)\n",
    "\n",
    "prRed(\"\\nRNN Scores :\")\n",
    "print(\"Train Score -->\", r2_score(y_train_pred,y_train))\n",
    "print(\"Test Score  -->\", r2_score(y_test_pred,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for RNN with best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_fn():\n",
    "    \n",
    "    rnn = Sequential()\n",
    "    rnn.add(Dense(33,input_dim=36,activation='relu'))\n",
    "    rnn.add(Dense(12,activation='relu'))\n",
    "    rnn.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    rnn.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_1 = KerasClassifier(build_fn = rnn_fn,verbose = 0)\n",
    "\n",
    "params = {'batch_size':[10,15,20],'epochs':[100,250,500]}\n",
    "rnn_grid = GridSearchCV(estimator=rnn_1 ,param_grid=params, cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000002561F924FC8>,\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'batch_size': [10, 15, 20], 'epochs': [100, 250, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN with the best parameters found -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "rnn = Sequential()\n",
    "#Additon of input layer\n",
    "rnn.add(Dense(36,input_dim=36,kernel_initializer='normal',activation='relu'))\n",
    "rnn.add(Dense(8,activation='relu',kernel_initializer='normal'))\n",
    "rnn.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(loss='mse',optimizer='adam',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1077/1077 [==============================] - 0s 207us/step - loss: 129954573.2071 - mse: 129954568.0000\n",
      "Epoch 2/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 129757442.0724 - mse: 129757448.0000 0s - loss: 129819824.3168 - mse: 129819840.000\n",
      "Epoch 3/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 128732760.9582 - mse: 128732784.0000\n",
      "Epoch 4/500\n",
      "1077/1077 [==============================] - 0s 125us/step - loss: 126121796.2266 - mse: 126121792.0000\n",
      "Epoch 5/500\n",
      "1077/1077 [==============================] - 0s 159us/step - loss: 121334624.8691 - mse: 121334624.0000\n",
      "Epoch 6/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 114145620.8951 - mse: 114145600.0000\n",
      "Epoch 7/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 104707306.7409 - mse: 104707288.0000\n",
      "Epoch 8/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 93447994.6741 - mse: 93448000.0000\n",
      "Epoch 9/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 81168872.0446 - mse: 81168864.0000\n",
      "Epoch 10/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 68802467.3203 - mse: 68802440.0000\n",
      "Epoch 11/500\n",
      "1077/1077 [==============================] - 0s 105us/step - loss: 57248789.3445 - mse: 57248800.0000\n",
      "Epoch 12/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 47279662.9526 - mse: 47279668.0000\n",
      "Epoch 13/500\n",
      "1077/1077 [==============================] - 0s 123us/step - loss: 39218084.2061 - mse: 39218080.0000\n",
      "Epoch 14/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 33082825.8422 - mse: 33082830.0000\n",
      "Epoch 15/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 28471987.7084 - mse: 28471990.0000\n",
      "Epoch 16/500\n",
      "1077/1077 [==============================] - 0s 115us/step - loss: 24900777.7790 - mse: 24900774.0000\n",
      "Epoch 17/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 21985408.2006 - mse: 21985410.0000\n",
      "Epoch 18/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 19446030.9944 - mse: 19446028.0000\n",
      "Epoch 19/500\n",
      "1077/1077 [==============================] - 0s 148us/step - loss: 17220363.9926 - mse: 17220362.0000\n",
      "Epoch 20/500\n",
      "1077/1077 [==============================] - 0s 118us/step - loss: 15265272.4420 - mse: 15265275.0000\n",
      "Epoch 21/500\n",
      "1077/1077 [==============================] - 0s 138us/step - loss: 13562582.6500 - mse: 13562583.0000\n",
      "Epoch 22/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 12118249.4090 - mse: 12118248.0000\n",
      "Epoch 23/500\n",
      "1077/1077 [==============================] - 0s 142us/step - loss: 10885416.2389 - mse: 10885415.0000\n",
      "Epoch 24/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 9853967.8078 - mse: 9853968.0000\n",
      "Epoch 25/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 8989120.1295 - mse: 8989122.0000\n",
      "Epoch 26/500\n",
      "1077/1077 [==============================] - 0s 167us/step - loss: 8266099.9406 - mse: 8266100.0000\n",
      "Epoch 27/500\n",
      "1077/1077 [==============================] - 0s 152us/step - loss: 7674343.8145 - mse: 7674346.0000\n",
      "Epoch 28/500\n",
      "1077/1077 [==============================] - 0s 151us/step - loss: 7160610.0501 - mse: 7160611.0000\n",
      "Epoch 29/500\n",
      "1077/1077 [==============================] - 0s 153us/step - loss: 6724662.9538 - mse: 6724663.5000\n",
      "Epoch 30/500\n",
      "1077/1077 [==============================] - 0s 153us/step - loss: 6346613.8122 - mse: 6346614.0000\n",
      "Epoch 31/500\n",
      "1077/1077 [==============================] - 0s 125us/step - loss: 6011085.6363 - mse: 6011087.0000\n",
      "Epoch 32/500\n",
      "1077/1077 [==============================] - 0s 149us/step - loss: 5715071.8870 - mse: 5715073.0000\n",
      "Epoch 33/500\n",
      "1077/1077 [==============================] - 0s 124us/step - loss: 5445426.8877 - mse: 5445427.0000\n",
      "Epoch 34/500\n",
      "1077/1077 [==============================] - 0s 206us/step - loss: 5201045.8069 - mse: 5201047.5000\n",
      "Epoch 35/500\n",
      "1077/1077 [==============================] - 0s 181us/step - loss: 4980862.0090 - mse: 4980862.0000\n",
      "Epoch 36/500\n",
      "1077/1077 [==============================] - 0s 138us/step - loss: 4779148.5337 - mse: 4779148.0000\n",
      "Epoch 37/500\n",
      "1077/1077 [==============================] - 0s 131us/step - loss: 4593617.7127 - mse: 4593616.5000\n",
      "Epoch 38/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 4423444.5780 - mse: 4423445.0000\n",
      "Epoch 39/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 4268167.1530 - mse: 4268168.0000\n",
      "Epoch 40/500\n",
      "1077/1077 [==============================] - 0s 130us/step - loss: 4117706.2499 - mse: 4117705.5000\n",
      "Epoch 41/500\n",
      "1077/1077 [==============================] - 0s 152us/step - loss: 3982376.0756 - mse: 3982376.2500\n",
      "Epoch 42/500\n",
      "1077/1077 [==============================] - 0s 154us/step - loss: 3856184.3537 - mse: 3856184.7500\n",
      "Epoch 43/500\n",
      "1077/1077 [==============================] - 0s 168us/step - loss: 3735480.7934 - mse: 3735480.7500\n",
      "Epoch 44/500\n",
      "1077/1077 [==============================] - 0s 118us/step - loss: 3628112.6082 - mse: 3628112.2500\n",
      "Epoch 45/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 3521651.6029 - mse: 3521653.0000\n",
      "Epoch 46/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 3417620.0425 - mse: 3417620.7500\n",
      "Epoch 47/500\n",
      "1077/1077 [==============================] - 0s 129us/step - loss: 3323344.6789 - mse: 3323344.2500\n",
      "Epoch 48/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 3232926.8695 - mse: 3232926.0000\n",
      "Epoch 49/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 3144180.9069 - mse: 3144180.0000\n",
      "Epoch 50/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 3064457.3847 - mse: 3064457.2500\n",
      "Epoch 51/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 2981502.8638 - mse: 2981503.2500\n",
      "Epoch 52/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 2903661.3935 - mse: 2903661.7500\n",
      "Epoch 53/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 2830805.8096 - mse: 2830805.5000\n",
      "Epoch 54/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 2758074.8307 - mse: 2758074.2500\n",
      "Epoch 55/500\n",
      "1077/1077 [==============================] - 0s 118us/step - loss: 2688730.0601 - mse: 2688730.2500\n",
      "Epoch 56/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 2622134.3150 - mse: 2622134.2500\n",
      "Epoch 57/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 2560670.5833 - mse: 2560671.0000\n",
      "Epoch 58/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 2493243.2882 - mse: 2493243.5000\n",
      "Epoch 59/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 2436487.6986 - mse: 2436487.2500\n",
      "Epoch 60/500\n",
      "1077/1077 [==============================] - 0s 134us/step - loss: 2374486.6987 - mse: 2374486.2500\n",
      "Epoch 61/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 2317364.1638 - mse: 2317363.7500\n",
      "Epoch 62/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 2261587.5276 - mse: 2261587.7500\n",
      "Epoch 63/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 2208650.2674 - mse: 2208650.2500\n",
      "Epoch 64/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 2157667.5435 - mse: 2157667.5000\n",
      "Epoch 65/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 2105914.7239 - mse: 2105914.2500\n",
      "Epoch 66/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 2061046.1668 - mse: 2061046.5000\n",
      "Epoch 67/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 2014636.5286 - mse: 2014636.6250\n",
      "Epoch 68/500\n",
      "1077/1077 [==============================] - ETA: 0s - loss: 2006801.2532 - mse: 2006801.750 - 0s 108us/step - loss: 1970911.0377 - mse: 1970911.5000\n",
      "Epoch 69/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 1927807.8568 - mse: 1927807.6250\n",
      "Epoch 70/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 1887283.2806 - mse: 1887283.6250\n",
      "Epoch 71/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 1847309.8273 - mse: 1847309.8750\n",
      "Epoch 72/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 1810026.5064 - mse: 1810026.7500\n",
      "Epoch 73/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1773486.1084 - mse: 1773486.2500\n",
      "Epoch 74/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 1739521.9222 - mse: 1739521.8750\n",
      "Epoch 75/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 1704682.6339 - mse: 1704682.5000\n",
      "Epoch 76/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 1672591.4805 - mse: 1672591.2500\n",
      "Epoch 77/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1641511.0866 - mse: 1641510.8750\n",
      "Epoch 78/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 1611976.6117 - mse: 1611976.6250\n",
      "Epoch 79/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 1584313.2878 - mse: 1584313.3750\n",
      "Epoch 80/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 1554453.3726 - mse: 1554453.1250\n",
      "Epoch 81/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1531257.7794 - mse: 1531258.1250\n",
      "Epoch 82/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1505913.7362 - mse: 1505913.8750\n",
      "Epoch 83/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1480625.9589 - mse: 1480626.0000\n",
      "Epoch 84/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 1459829.0141 - mse: 1459828.8750\n",
      "Epoch 85/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1435806.1764 - mse: 1435805.8750\n",
      "Epoch 86/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1416958.7376 - mse: 1416958.7500\n",
      "Epoch 87/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1394802.2808 - mse: 1394802.6250\n",
      "Epoch 88/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1377090.8816 - mse: 1377090.8750\n",
      "Epoch 89/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1358419.5167 - mse: 1358419.3750\n",
      "Epoch 90/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 1340903.6320 - mse: 1340904.0000\n",
      "Epoch 91/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 1327610.2369 - mse: 1327610.5000\n",
      "Epoch 92/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 1308864.0045 - mse: 1308864.0000\n",
      "Epoch 93/500\n",
      "1077/1077 [==============================] - 0s 124us/step - loss: 1293995.2016 - mse: 1293995.0000\n",
      "Epoch 94/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 1281193.1494 - mse: 1281192.8750\n",
      "Epoch 95/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 1264399.7696 - mse: 1264399.6250\n",
      "Epoch 96/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1253444.1925 - mse: 1253444.2500\n",
      "Epoch 97/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 1240394.2687 - mse: 1240394.2500\n",
      "Epoch 98/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1226667.4310 - mse: 1226667.5000\n",
      "Epoch 99/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 1215487.0004 - mse: 1215486.8750\n",
      "Epoch 100/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 1207165.4106 - mse: 1207165.5000\n",
      "Epoch 101/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 1193583.6371 - mse: 1193584.0000\n",
      "Epoch 102/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 1184965.6840 - mse: 1184965.6250\n",
      "Epoch 103/500\n",
      "1077/1077 [==============================] - 0s 105us/step - loss: 1171751.5625 - mse: 1171751.6250\n",
      "Epoch 104/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 1164077.5337 - mse: 1164077.3750\n",
      "Epoch 105/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1155496.0084 - mse: 1155496.2500\n",
      "Epoch 106/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1145617.5586 - mse: 1145617.7500\n",
      "Epoch 107/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 1137974.8952 - mse: 1137974.8750\n",
      "Epoch 108/500\n",
      "1077/1077 [==============================] - 0s 105us/step - loss: 1127526.6548 - mse: 1127526.7500\n",
      "Epoch 109/500\n",
      "1077/1077 [==============================] - 0s 105us/step - loss: 1121035.8789 - mse: 1121035.5000\n",
      "Epoch 110/500\n",
      "1077/1077 [==============================] - 0s 105us/step - loss: 1116325.2886 - mse: 1116325.3750\n",
      "Epoch 111/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1107215.2532 - mse: 1107215.0000\n",
      "Epoch 112/500\n",
      "1077/1077 [==============================] - 0s 105us/step - loss: 1100683.4979 - mse: 1100683.5000\n",
      "Epoch 113/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1091633.2822 - mse: 1091633.5000\n",
      "Epoch 114/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 1085629.4301 - mse: 1085629.6250\n",
      "Epoch 115/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1081235.5592 - mse: 1081235.6250\n",
      "Epoch 116/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 1073255.0187 - mse: 1073255.1250\n",
      "Epoch 117/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1064964.3976 - mse: 1064964.5000\n",
      "Epoch 118/500\n",
      "1077/1077 [==============================] - 0s 140us/step - loss: 1060352.1935 - mse: 1060352.3750\n",
      "Epoch 119/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1055340.0171 - mse: 1055340.2500\n",
      "Epoch 120/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1051360.1269 - mse: 1051360.1250\n",
      "Epoch 121/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 1044686.4867 - mse: 1044686.3125\n",
      "Epoch 122/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 1038581.2368 - mse: 1038581.0625\n",
      "Epoch 123/500\n",
      "1077/1077 [==============================] - 0s 141us/step - loss: 1036053.3783 - mse: 1036053.2500\n",
      "Epoch 124/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1029038.2192 - mse: 1029038.1250\n",
      "Epoch 125/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 1026903.7027 - mse: 1026903.6875\n",
      "Epoch 126/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 1023149.9437 - mse: 1023150.0000\n",
      "Epoch 127/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 1016413.7857 - mse: 1016413.7500\n",
      "Epoch 128/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1012344.3145 - mse: 1012344.3750\n",
      "Epoch 129/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 1008518.6433 - mse: 1008518.5625\n",
      "Epoch 130/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 1002514.7397 - mse: 1002514.7500\n",
      "Epoch 131/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 998224.6943 - mse: 998224.5625\n",
      "Epoch 132/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 995125.9339 - mse: 995126.0625\n",
      "Epoch 133/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 990733.2129 - mse: 990733.0625\n",
      "Epoch 134/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 987020.9458 - mse: 987020.8750\n",
      "Epoch 135/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 983167.0837 - mse: 983167.1875\n",
      "Epoch 136/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 979412.1798 - mse: 979412.3125\n",
      "Epoch 137/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 977013.8079 - mse: 977013.7500\n",
      "Epoch 138/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 970614.2205 - mse: 970614.2500\n",
      "Epoch 139/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 968543.6072 - mse: 968543.3125\n",
      "Epoch 140/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 963714.0794 - mse: 963713.8125\n",
      "Epoch 141/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 961824.0691 - mse: 961824.0000\n",
      "Epoch 142/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 959398.8562 - mse: 959399.0000\n",
      "Epoch 143/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 955986.1853 - mse: 955986.0625\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077/1077 [==============================] - 0s 125us/step - loss: 952910.7739 - mse: 952911.0000\n",
      "Epoch 145/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 949245.7888 - mse: 949245.6875\n",
      "Epoch 146/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 944300.3243 - mse: 944300.2500\n",
      "Epoch 147/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 944812.1682 - mse: 944811.7500\n",
      "Epoch 148/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 938257.4884 - mse: 938257.3125\n",
      "Epoch 149/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 936442.7565 - mse: 936442.8750\n",
      "Epoch 150/500\n",
      "1077/1077 [==============================] - 0s 105us/step - loss: 934409.7794 - mse: 934409.6875\n",
      "Epoch 151/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 931453.7853 - mse: 931453.7500\n",
      "Epoch 152/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 928996.0831 - mse: 928996.1250\n",
      "Epoch 153/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 925550.9962 - mse: 925550.5000\n",
      "Epoch 154/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 924429.3984 - mse: 924429.4375\n",
      "Epoch 155/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 919027.6063 - mse: 919027.5000\n",
      "Epoch 156/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 920184.7642 - mse: 920184.5000\n",
      "Epoch 157/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 915857.3216 - mse: 915857.5000\n",
      "Epoch 158/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 912604.7419 - mse: 912604.6875\n",
      "Epoch 159/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 913530.5065 - mse: 913530.5625\n",
      "Epoch 160/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 909404.7597 - mse: 909404.6875\n",
      "Epoch 161/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 906083.8047 - mse: 906083.8750\n",
      "Epoch 162/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 903432.9366 - mse: 903432.9375\n",
      "Epoch 163/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 900354.4591 - mse: 900354.5000\n",
      "Epoch 164/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 898740.5185 - mse: 898740.3125\n",
      "Epoch 165/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 896156.3471 - mse: 896156.3750\n",
      "Epoch 166/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 893855.3552 - mse: 893855.5000\n",
      "Epoch 167/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 892552.7660 - mse: 892552.8125\n",
      "Epoch 168/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 890898.9598 - mse: 890898.6875\n",
      "Epoch 169/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 887967.1672 - mse: 887967.1250\n",
      "Epoch 170/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 886223.4562 - mse: 886223.3125\n",
      "Epoch 171/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 886030.9753 - mse: 886031.3125\n",
      "Epoch 172/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 882215.6349 - mse: 882215.8750\n",
      "Epoch 173/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 877969.4843 - mse: 877969.3750\n",
      "Epoch 174/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 877260.7196 - mse: 877260.8125\n",
      "Epoch 175/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 875983.1329 - mse: 875983.1250\n",
      "Epoch 176/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 872961.9054 - mse: 872962.0000\n",
      "Epoch 177/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 872082.9079 - mse: 872082.8125\n",
      "Epoch 178/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 871892.4253 - mse: 871892.6875\n",
      "Epoch 179/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 868319.9360 - mse: 868319.8750\n",
      "Epoch 180/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 865931.5264 - mse: 865931.6250\n",
      "Epoch 181/500\n",
      "1077/1077 [==============================] - 0s 119us/step - loss: 864422.5847 - mse: 864422.3750\n",
      "Epoch 182/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 862202.6741 - mse: 862202.6875\n",
      "Epoch 183/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 860982.8783 - mse: 860982.7500\n",
      "Epoch 184/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 860682.4440 - mse: 860682.3750\n",
      "Epoch 185/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 859931.7463 - mse: 859931.9375\n",
      "Epoch 186/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 857796.9196 - mse: 857797.0625\n",
      "Epoch 187/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 855607.1805 - mse: 855607.0625\n",
      "Epoch 188/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 852876.9053 - mse: 852876.8125\n",
      "Epoch 189/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 851315.6709 - mse: 851315.5625\n",
      "Epoch 190/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 850669.9409 - mse: 850669.8125\n",
      "Epoch 191/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 847116.2744 - mse: 847116.2500\n",
      "Epoch 192/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 846196.3020 - mse: 846196.5000\n",
      "Epoch 193/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 847472.9767 - mse: 847473.0000\n",
      "Epoch 194/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 845782.3475 - mse: 845782.3750\n",
      "Epoch 195/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 842026.1258 - mse: 842025.9375\n",
      "Epoch 196/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 841180.9599 - mse: 841180.7500\n",
      "Epoch 197/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 838088.6524 - mse: 838088.5625\n",
      "Epoch 198/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 838808.2535 - mse: 838808.3750\n",
      "Epoch 199/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 837726.2475 - mse: 837726.3125\n",
      "Epoch 200/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 834787.5921 - mse: 834787.6250\n",
      "Epoch 201/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 832607.2914 - mse: 832607.1875\n",
      "Epoch 202/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 834983.6715 - mse: 834983.6875\n",
      "Epoch 203/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 829578.8142 - mse: 829578.7500\n",
      "Epoch 204/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 830422.0046 - mse: 830422.2500\n",
      "Epoch 205/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 828964.1915 - mse: 828964.0625\n",
      "Epoch 206/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 825515.4695 - mse: 825515.6875\n",
      "Epoch 207/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 825065.1121 - mse: 825065.1875\n",
      "Epoch 208/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 825570.2100 - mse: 825570.1875\n",
      "Epoch 209/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 822845.7708 - mse: 822845.8750\n",
      "Epoch 210/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 822040.2250 - mse: 822040.1875\n",
      "Epoch 211/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 818065.8959 - mse: 818065.8125\n",
      "Epoch 212/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 817921.1328 - mse: 817921.0000\n",
      "Epoch 213/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 817288.4061 - mse: 817288.4375\n",
      "Epoch 214/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 817183.1651 - mse: 817183.0625\n",
      "Epoch 215/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 816145.8332 - mse: 816145.8750\n",
      "Epoch 216/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 814682.0240 - mse: 814681.9375\n",
      "Epoch 217/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 812821.6790 - mse: 812821.8125\n",
      "Epoch 218/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 812173.6055 - mse: 812173.7500\n",
      "Epoch 219/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 809550.2173 - mse: 809550.0000\n",
      "Epoch 220/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 809109.8054 - mse: 809109.8125\n",
      "Epoch 221/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 808813.4501 - mse: 808813.5000\n",
      "Epoch 222/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 805067.3703 - mse: 805067.4375\n",
      "Epoch 223/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 807288.6093 - mse: 807288.6250\n",
      "Epoch 224/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 803468.4271 - mse: 803468.4375\n",
      "Epoch 225/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 805353.2202 - mse: 805353.5625\n",
      "Epoch 226/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 803946.1327 - mse: 803946.3125\n",
      "Epoch 227/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 801533.9479 - mse: 801533.9375\n",
      "Epoch 228/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 800901.7043 - mse: 800901.6875\n",
      "Epoch 229/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 798372.2325 - mse: 798372.1250\n",
      "Epoch 230/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 797191.7103 - mse: 797191.8125\n",
      "Epoch 231/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 797232.1840 - mse: 797232.2500\n",
      "Epoch 232/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 795446.5553 - mse: 795446.5000\n",
      "Epoch 233/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 794117.4849 - mse: 794117.5000\n",
      "Epoch 234/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 792177.2907 - mse: 792177.1875\n",
      "Epoch 235/500\n",
      "1077/1077 [==============================] - 0s 115us/step - loss: 792829.8304 - mse: 792829.8125\n",
      "Epoch 236/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 792272.7137 - mse: 792272.6875\n",
      "Epoch 237/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 790891.3678 - mse: 790891.3125\n",
      "Epoch 238/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 792145.1235 - mse: 792144.9375\n",
      "Epoch 239/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 789252.9214 - mse: 789252.9375\n",
      "Epoch 240/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 787073.1424 - mse: 787073.1250\n",
      "Epoch 241/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 789244.6627 - mse: 789244.5625\n",
      "Epoch 242/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 786873.9242 - mse: 786873.6875\n",
      "Epoch 243/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 784550.9190 - mse: 784550.9375\n",
      "Epoch 244/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 783687.5899 - mse: 783687.4375\n",
      "Epoch 245/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 782231.7680 - mse: 782231.8750\n",
      "Epoch 246/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 780162.3101 - mse: 780162.3750\n",
      "Epoch 247/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 781948.0740 - mse: 781948.0625\n",
      "Epoch 248/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 778505.7427 - mse: 778505.9375\n",
      "Epoch 249/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 778582.6883 - mse: 778582.6875\n",
      "Epoch 250/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 779308.1492 - mse: 779308.0000\n",
      "Epoch 251/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 776950.6027 - mse: 776950.8125\n",
      "Epoch 252/500\n",
      "1077/1077 [==============================] - 0s 106us/step - loss: 775864.0583 - mse: 775864.0000\n",
      "Epoch 253/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 776858.3113 - mse: 776858.0625\n",
      "Epoch 254/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 774431.2863 - mse: 774431.0000\n",
      "Epoch 255/500\n",
      "1077/1077 [==============================] - 0s 131us/step - loss: 774605.9347 - mse: 774605.8125\n",
      "Epoch 256/500\n",
      "1077/1077 [==============================] - 0s 194us/step - loss: 773443.2870 - mse: 773443.0625\n",
      "Epoch 257/500\n",
      "1077/1077 [==============================] - 0s 456us/step - loss: 773738.8354 - mse: 773738.8750\n",
      "Epoch 258/500\n",
      "1077/1077 [==============================] - 0s 425us/step - loss: 771271.0122 - mse: 771270.8750 0s - loss: 725877.6847 - mse: 72587\n",
      "Epoch 259/500\n",
      "1077/1077 [==============================] - 0s 302us/step - loss: 770024.5609 - mse: 770024.5625\n",
      "Epoch 260/500\n",
      "1077/1077 [==============================] - 0s 347us/step - loss: 770154.6739 - mse: 770154.5625\n",
      "Epoch 261/500\n",
      "1077/1077 [==============================] - 0s 294us/step - loss: 769469.8714 - mse: 769469.6875\n",
      "Epoch 262/500\n",
      "1077/1077 [==============================] - 0s 240us/step - loss: 766126.5734 - mse: 766126.5000\n",
      "Epoch 263/500\n",
      "1077/1077 [==============================] - 0s 380us/step - loss: 766711.9958 - mse: 766712.0625\n",
      "Epoch 264/500\n",
      "1077/1077 [==============================] - 0s 225us/step - loss: 765894.2551 - mse: 765894.5625\n",
      "Epoch 265/500\n",
      "1077/1077 [==============================] - 0s 173us/step - loss: 764852.8949 - mse: 764852.8125\n",
      "Epoch 266/500\n",
      "1077/1077 [==============================] - 0s 130us/step - loss: 763682.7049 - mse: 763682.5000\n",
      "Epoch 267/500\n",
      "1077/1077 [==============================] - 0s 156us/step - loss: 762409.7445 - mse: 762409.6875\n",
      "Epoch 268/500\n",
      "1077/1077 [==============================] - 0s 184us/step - loss: 761570.5207 - mse: 761570.6250\n",
      "Epoch 269/500\n",
      "1077/1077 [==============================] - 0s 200us/step - loss: 761695.1859 - mse: 761694.9375\n",
      "Epoch 270/500\n",
      "1077/1077 [==============================] - 0s 128us/step - loss: 759445.4377 - mse: 759445.6250\n",
      "Epoch 271/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 759845.2624 - mse: 759845.2500\n",
      "Epoch 272/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 760563.5021 - mse: 760563.4375\n",
      "Epoch 273/500\n",
      "1077/1077 [==============================] - 0s 104us/step - loss: 758112.1955 - mse: 758112.1250\n",
      "Epoch 274/500\n",
      "1077/1077 [==============================] - 0s 132us/step - loss: 756695.8507 - mse: 756696.0000\n",
      "Epoch 275/500\n",
      "1077/1077 [==============================] - 0s 121us/step - loss: 756450.9515 - mse: 756451.2500\n",
      "Epoch 276/500\n",
      "1077/1077 [==============================] - 0s 118us/step - loss: 755140.6052 - mse: 755140.4375\n",
      "Epoch 277/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 755620.4622 - mse: 755620.5625\n",
      "Epoch 278/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 756474.8211 - mse: 756474.6875\n",
      "Epoch 279/500\n",
      "1077/1077 [==============================] - 0s 125us/step - loss: 754046.7886 - mse: 754046.8750\n",
      "Epoch 280/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 753572.0784 - mse: 753572.0000\n",
      "Epoch 281/500\n",
      "1077/1077 [==============================] - 0s 151us/step - loss: 752125.4914 - mse: 752125.3125\n",
      "Epoch 282/500\n",
      "1077/1077 [==============================] - 0s 134us/step - loss: 753833.3060 - mse: 753833.3125\n",
      "Epoch 283/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 750501.5932 - mse: 750501.5000\n",
      "Epoch 284/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 751779.0651 - mse: 751779.3125\n",
      "Epoch 285/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 749433.4128 - mse: 749433.4375\n",
      "Epoch 286/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 748872.5386 - mse: 748872.3750\n",
      "Epoch 287/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 748502.2489 - mse: 748502.2500\n",
      "Epoch 288/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 746922.3620 - mse: 746922.3750\n",
      "Epoch 289/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 749407.4869 - mse: 749407.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 745496.8811 - mse: 745497.0000\n",
      "Epoch 291/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 746500.6000 - mse: 746500.4375\n",
      "Epoch 292/500\n",
      "1077/1077 [==============================] - 0s 140us/step - loss: 744619.9179 - mse: 744620.0000\n",
      "Epoch 293/500\n",
      "1077/1077 [==============================] - 0s 132us/step - loss: 743413.8267 - mse: 743413.8125\n",
      "Epoch 294/500\n",
      "1077/1077 [==============================] - 0s 131us/step - loss: 741514.1993 - mse: 741514.2500\n",
      "Epoch 295/500\n",
      "1077/1077 [==============================] - 0s 143us/step - loss: 742578.7214 - mse: 742578.5625\n",
      "Epoch 296/500\n",
      "1077/1077 [==============================] - 0s 168us/step - loss: 741476.5953 - mse: 741476.6250\n",
      "Epoch 297/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 739498.6693 - mse: 739498.8750\n",
      "Epoch 298/500\n",
      "1077/1077 [==============================] - 0s 277us/step - loss: 742331.0832 - mse: 742330.8750\n",
      "Epoch 299/500\n",
      "1077/1077 [==============================] - 0s 264us/step - loss: 739466.8804 - mse: 739466.8125\n",
      "Epoch 300/500\n",
      "1077/1077 [==============================] - 0s 243us/step - loss: 738598.0907 - mse: 738598.0625\n",
      "Epoch 301/500\n",
      "1077/1077 [==============================] - 0s 180us/step - loss: 738623.7150 - mse: 738623.9375\n",
      "Epoch 302/500\n",
      "1077/1077 [==============================] - 0s 120us/step - loss: 738570.9112 - mse: 738570.9375\n",
      "Epoch 303/500\n",
      "1077/1077 [==============================] - 0s 126us/step - loss: 735662.3880 - mse: 735662.5000\n",
      "Epoch 304/500\n",
      "1077/1077 [==============================] - 0s 139us/step - loss: 740220.3625 - mse: 740220.3750\n",
      "Epoch 305/500\n",
      "1077/1077 [==============================] - 0s 149us/step - loss: 735706.4651 - mse: 735706.6250\n",
      "Epoch 306/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 735459.7051 - mse: 735459.8125\n",
      "Epoch 307/500\n",
      "1077/1077 [==============================] - 0s 147us/step - loss: 733820.7755 - mse: 733820.8750\n",
      "Epoch 308/500\n",
      "1077/1077 [==============================] - 0s 145us/step - loss: 735035.0289 - mse: 735034.9375\n",
      "Epoch 309/500\n",
      "1077/1077 [==============================] - 0s 121us/step - loss: 731709.4690 - mse: 731709.3750\n",
      "Epoch 310/500\n",
      "1077/1077 [==============================] - 0s 199us/step - loss: 731764.4809 - mse: 731764.4375\n",
      "Epoch 311/500\n",
      "1077/1077 [==============================] - 0s 234us/step - loss: 730922.1471 - mse: 730922.1875\n",
      "Epoch 312/500\n",
      "1077/1077 [==============================] - 0s 183us/step - loss: 732897.0221 - mse: 732897.1250\n",
      "Epoch 313/500\n",
      "1077/1077 [==============================] - 0s 179us/step - loss: 730448.0075 - mse: 730447.9375\n",
      "Epoch 314/500\n",
      "1077/1077 [==============================] - 0s 133us/step - loss: 730509.2611 - mse: 730509.3125\n",
      "Epoch 315/500\n",
      "1077/1077 [==============================] - 0s 216us/step - loss: 730845.8168 - mse: 730845.8750\n",
      "Epoch 316/500\n",
      "1077/1077 [==============================] - 0s 209us/step - loss: 728850.1275 - mse: 728850.2500\n",
      "Epoch 317/500\n",
      "1077/1077 [==============================] - 0s 156us/step - loss: 728677.9158 - mse: 728678.0000\n",
      "Epoch 318/500\n",
      "1077/1077 [==============================] - 0s 128us/step - loss: 726892.8724 - mse: 726892.8125\n",
      "Epoch 319/500\n",
      "1077/1077 [==============================] - 0s 177us/step - loss: 728413.8890 - mse: 728413.6875\n",
      "Epoch 320/500\n",
      "1077/1077 [==============================] - 0s 251us/step - loss: 726582.5458 - mse: 726582.6250\n",
      "Epoch 321/500\n",
      "1077/1077 [==============================] - 0s 159us/step - loss: 726362.5574 - mse: 726362.6875\n",
      "Epoch 322/500\n",
      "1077/1077 [==============================] - 0s 141us/step - loss: 726492.5119 - mse: 726492.4375\n",
      "Epoch 323/500\n",
      "1077/1077 [==============================] - 0s 141us/step - loss: 724904.1501 - mse: 724904.2500\n",
      "Epoch 324/500\n",
      "1077/1077 [==============================] - 0s 157us/step - loss: 724622.6544 - mse: 724622.5625\n",
      "Epoch 325/500\n",
      "1077/1077 [==============================] - 0s 175us/step - loss: 722183.2725 - mse: 722183.3750\n",
      "Epoch 326/500\n",
      "1077/1077 [==============================] - 0s 187us/step - loss: 725203.3453 - mse: 725203.3125\n",
      "Epoch 327/500\n",
      "1077/1077 [==============================] - 0s 210us/step - loss: 722770.8129 - mse: 722770.6875\n",
      "Epoch 328/500\n",
      "1077/1077 [==============================] - 0s 116us/step - loss: 722214.2829 - mse: 722214.1875\n",
      "Epoch 329/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 720961.8669 - mse: 720961.6875\n",
      "Epoch 330/500\n",
      "1077/1077 [==============================] - 0s 206us/step - loss: 720682.7831 - mse: 720682.8750\n",
      "Epoch 331/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 719650.3018 - mse: 719650.3750\n",
      "Epoch 332/500\n",
      "1077/1077 [==============================] - 0s 129us/step - loss: 719207.2191 - mse: 719207.1875\n",
      "Epoch 333/500\n",
      "1077/1077 [==============================] - 0s 200us/step - loss: 718129.1781 - mse: 718129.0000\n",
      "Epoch 334/500\n",
      "1077/1077 [==============================] - 0s 121us/step - loss: 718345.4749 - mse: 718345.3125\n",
      "Epoch 335/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 715545.8809 - mse: 715545.7500\n",
      "Epoch 336/500\n",
      "1077/1077 [==============================] - 0s 224us/step - loss: 716594.2495 - mse: 716594.3750\n",
      "Epoch 337/500\n",
      "1077/1077 [==============================] - 0s 149us/step - loss: 718111.9472 - mse: 718111.8750\n",
      "Epoch 338/500\n",
      "1077/1077 [==============================] - 0s 124us/step - loss: 714556.1756 - mse: 714556.1250\n",
      "Epoch 339/500\n",
      "1077/1077 [==============================] - 0s 203us/step - loss: 716304.9898 - mse: 716304.9375\n",
      "Epoch 340/500\n",
      "1077/1077 [==============================] - 0s 162us/step - loss: 714343.0143 - mse: 714343.0625\n",
      "Epoch 341/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 715543.4910 - mse: 715543.5625\n",
      "Epoch 342/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 713655.2359 - mse: 713655.3125\n",
      "Epoch 343/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 713939.5741 - mse: 713939.6875\n",
      "Epoch 344/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 713052.4320 - mse: 713052.3750\n",
      "Epoch 345/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 711646.6765 - mse: 711646.4375\n",
      "Epoch 346/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 714530.3205 - mse: 714530.3125\n",
      "Epoch 347/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 710947.5733 - mse: 710947.7500\n",
      "Epoch 348/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 710267.4724 - mse: 710267.5625\n",
      "Epoch 349/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 709176.4657 - mse: 709176.5625\n",
      "Epoch 350/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 709278.2874 - mse: 709278.4375\n",
      "Epoch 351/500\n",
      "1077/1077 [==============================] - 0s 154us/step - loss: 709932.8664 - mse: 709932.9375\n",
      "Epoch 352/500\n",
      "1077/1077 [==============================] - 0s 254us/step - loss: 708281.3769 - mse: 708281.4375\n",
      "Epoch 353/500\n",
      "1077/1077 [==============================] - 0s 187us/step - loss: 708709.4131 - mse: 708709.4375\n",
      "Epoch 354/500\n",
      "1077/1077 [==============================] - 0s 132us/step - loss: 706844.8903 - mse: 706844.7500\n",
      "Epoch 355/500\n",
      "1077/1077 [==============================] - 0s 128us/step - loss: 707007.0050 - mse: 707007.0625\n",
      "Epoch 356/500\n",
      "1077/1077 [==============================] - 0s 169us/step - loss: 709022.5686 - mse: 709022.4375\n",
      "Epoch 357/500\n",
      "1077/1077 [==============================] - 0s 178us/step - loss: 707386.1364 - mse: 707386.0625\n",
      "Epoch 358/500\n",
      "1077/1077 [==============================] - 0s 158us/step - loss: 704755.2470 - mse: 704755.3125\n",
      "Epoch 359/500\n",
      "1077/1077 [==============================] - 0s 218us/step - loss: 702730.6230 - mse: 702730.8125\n",
      "Epoch 360/500\n",
      "1077/1077 [==============================] - 0s 208us/step - loss: 703539.9295 - mse: 703539.7500\n",
      "Epoch 361/500\n",
      "1077/1077 [==============================] - 0s 141us/step - loss: 704067.5839 - mse: 704067.6250\n",
      "Epoch 362/500\n",
      "1077/1077 [==============================] - 0s 174us/step - loss: 702302.2571 - mse: 702302.3750\n",
      "Epoch 363/500\n",
      "1077/1077 [==============================] - 0s 200us/step - loss: 702630.4000 - mse: 702630.4375\n",
      "Epoch 364/500\n",
      "1077/1077 [==============================] - 0s 134us/step - loss: 701887.9299 - mse: 701887.8750\n",
      "Epoch 365/500\n",
      "1077/1077 [==============================] - 0s 123us/step - loss: 699712.4269 - mse: 699712.3125\n",
      "Epoch 366/500\n",
      "1077/1077 [==============================] - 0s 198us/step - loss: 701923.1948 - mse: 701923.3750\n",
      "Epoch 367/500\n",
      "1077/1077 [==============================] - 0s 125us/step - loss: 700499.6638 - mse: 700499.8125\n",
      "Epoch 368/500\n",
      "1077/1077 [==============================] - 0s 134us/step - loss: 700685.8972 - mse: 700686.0000\n",
      "Epoch 369/500\n",
      "1077/1077 [==============================] - 0s 150us/step - loss: 698346.8463 - mse: 698346.8125\n",
      "Epoch 370/500\n",
      "1077/1077 [==============================] - 0s 131us/step - loss: 699485.0715 - mse: 699485.0625\n",
      "Epoch 371/500\n",
      "1077/1077 [==============================] - 0s 127us/step - loss: 698967.9130 - mse: 698967.8125\n",
      "Epoch 372/500\n",
      "1077/1077 [==============================] - 0s 124us/step - loss: 697907.0912 - mse: 697907.1250\n",
      "Epoch 373/500\n",
      "1077/1077 [==============================] - 0s 128us/step - loss: 701373.7768 - mse: 701373.8125\n",
      "Epoch 374/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 695053.0843 - mse: 695053.0625\n",
      "Epoch 375/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 696389.5129 - mse: 696389.4375\n",
      "Epoch 376/500\n",
      "1077/1077 [==============================] - 0s 112us/step - loss: 695218.8237 - mse: 695219.0000\n",
      "Epoch 377/500\n",
      "1077/1077 [==============================] - 0s 131us/step - loss: 694518.1492 - mse: 694518.0625\n",
      "Epoch 378/500\n",
      "1077/1077 [==============================] - 0s 121us/step - loss: 694870.6670 - mse: 694870.6875\n",
      "Epoch 379/500\n",
      "1077/1077 [==============================] - 0s 130us/step - loss: 694905.7258 - mse: 694905.8125\n",
      "Epoch 380/500\n",
      "1077/1077 [==============================] - 0s 114us/step - loss: 694009.2382 - mse: 694009.3750\n",
      "Epoch 381/500\n",
      "1077/1077 [==============================] - 0s 130us/step - loss: 692149.6662 - mse: 692149.6875\n",
      "Epoch 382/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 692702.6741 - mse: 692702.8125\n",
      "Epoch 383/500\n",
      "1077/1077 [==============================] - 0s 155us/step - loss: 691476.3441 - mse: 691476.3750\n",
      "Epoch 384/500\n",
      "1077/1077 [==============================] - 0s 160us/step - loss: 694038.9486 - mse: 694039.1250\n",
      "Epoch 385/500\n",
      "1077/1077 [==============================] - 0s 155us/step - loss: 690503.1822 - mse: 690503.2500\n",
      "Epoch 386/500\n",
      "1077/1077 [==============================] - 0s 141us/step - loss: 690848.1998 - mse: 690848.3750\n",
      "Epoch 387/500\n",
      "1077/1077 [==============================] - 0s 137us/step - loss: 690636.4766 - mse: 690636.4375\n",
      "Epoch 388/500\n",
      "1077/1077 [==============================] - 0s 146us/step - loss: 688625.9471 - mse: 688625.9375\n",
      "Epoch 389/500\n",
      "1077/1077 [==============================] - 0s 160us/step - loss: 688965.8486 - mse: 688965.8750\n",
      "Epoch 390/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 688669.8478 - mse: 688669.6875\n",
      "Epoch 391/500\n",
      "1077/1077 [==============================] - 0s 134us/step - loss: 688887.8855 - mse: 688887.9375\n",
      "Epoch 392/500\n",
      "1077/1077 [==============================] - 0s 222us/step - loss: 687557.0637 - mse: 687557.0000\n",
      "Epoch 393/500\n",
      "1077/1077 [==============================] - 0s 139us/step - loss: 687233.1880 - mse: 687233.0625\n",
      "Epoch 394/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 687086.7337 - mse: 687087.0000\n",
      "Epoch 395/500\n",
      "1077/1077 [==============================] - 0s 127us/step - loss: 686039.9597 - mse: 686039.7500\n",
      "Epoch 396/500\n",
      "1077/1077 [==============================] - 0s 139us/step - loss: 684976.9568 - mse: 684976.9375\n",
      "Epoch 397/500\n",
      "1077/1077 [==============================] - 0s 142us/step - loss: 685814.5622 - mse: 685814.6875\n",
      "Epoch 398/500\n",
      "1077/1077 [==============================] - 0s 128us/step - loss: 684606.7191 - mse: 684606.6875\n",
      "Epoch 399/500\n",
      "1077/1077 [==============================] - 0s 144us/step - loss: 683557.9104 - mse: 683558.0000\n",
      "Epoch 400/500\n",
      "1077/1077 [==============================] - 0s 163us/step - loss: 683959.0169 - mse: 683958.9375\n",
      "Epoch 401/500\n",
      "1077/1077 [==============================] - 0s 124us/step - loss: 682882.0684 - mse: 682882.0625\n",
      "Epoch 402/500\n",
      "1077/1077 [==============================] - 0s 152us/step - loss: 681679.1478 - mse: 681679.1250\n",
      "Epoch 403/500\n",
      "1077/1077 [==============================] - 0s 123us/step - loss: 681031.3896 - mse: 681031.5625\n",
      "Epoch 404/500\n",
      "1077/1077 [==============================] - 0s 146us/step - loss: 680281.7923 - mse: 680281.8750\n",
      "Epoch 405/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 680604.1101 - mse: 680604.3125\n",
      "Epoch 406/500\n",
      "1077/1077 [==============================] - 0s 124us/step - loss: 679683.2438 - mse: 679683.3750\n",
      "Epoch 407/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 682140.7219 - mse: 682140.6875\n",
      "Epoch 408/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 679473.3130 - mse: 679473.1250\n",
      "Epoch 409/500\n",
      "1077/1077 [==============================] - 0s 167us/step - loss: 679300.3983 - mse: 679300.3750\n",
      "Epoch 410/500\n",
      "1077/1077 [==============================] - 0s 212us/step - loss: 678204.7101 - mse: 678204.6875\n",
      "Epoch 411/500\n",
      "1077/1077 [==============================] - 0s 151us/step - loss: 676193.0757 - mse: 676192.6875\n",
      "Epoch 412/500\n",
      "1077/1077 [==============================] - 0s 172us/step - loss: 676330.8472 - mse: 676330.8750\n",
      "Epoch 413/500\n",
      "1077/1077 [==============================] - 0s 163us/step - loss: 676891.8800 - mse: 676891.6875\n",
      "Epoch 414/500\n",
      "1077/1077 [==============================] - 0s 229us/step - loss: 675783.8882 - mse: 675783.6875\n",
      "Epoch 415/500\n",
      "1077/1077 [==============================] - 0s 222us/step - loss: 675180.5863 - mse: 675180.5625\n",
      "Epoch 416/500\n",
      "1077/1077 [==============================] - 0s 156us/step - loss: 673202.0183 - mse: 673202.0000\n",
      "Epoch 417/500\n",
      "1077/1077 [==============================] - 0s 154us/step - loss: 676191.7862 - mse: 676191.8750\n",
      "Epoch 418/500\n",
      "1077/1077 [==============================] - 0s 140us/step - loss: 673916.8128 - mse: 673916.8750\n",
      "Epoch 419/500\n",
      "1077/1077 [==============================] - 0s 132us/step - loss: 673424.4188 - mse: 673424.3750\n",
      "Epoch 420/500\n",
      "1077/1077 [==============================] - 0s 136us/step - loss: 672986.4914 - mse: 672986.3750\n",
      "Epoch 421/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 672469.0586 - mse: 672469.0625\n",
      "Epoch 422/500\n",
      "1077/1077 [==============================] - 0s 123us/step - loss: 672723.4490 - mse: 672723.1875\n",
      "Epoch 423/500\n",
      "1077/1077 [==============================] - 0s 165us/step - loss: 672124.8966 - mse: 672124.9375\n",
      "Epoch 424/500\n",
      "1077/1077 [==============================] - 0s 166us/step - loss: 671659.1274 - mse: 671659.1250 0s - loss: 602078.3136 - mse: 602078.3\n",
      "Epoch 425/500\n",
      "1077/1077 [==============================] - 0s 139us/step - loss: 674092.2591 - mse: 674092.0625\n",
      "Epoch 426/500\n",
      "1077/1077 [==============================] - 0s 136us/step - loss: 671983.1783 - mse: 671983.1875\n",
      "Epoch 427/500\n",
      "1077/1077 [==============================] - 0s 138us/step - loss: 669433.7420 - mse: 669434.0000\n",
      "Epoch 428/500\n",
      "1077/1077 [==============================] - 0s 146us/step - loss: 668512.1612 - mse: 668512.1875\n",
      "Epoch 429/500\n",
      "1077/1077 [==============================] - 0s 212us/step - loss: 670074.6599 - mse: 670074.6875\n",
      "Epoch 430/500\n",
      "1077/1077 [==============================] - 0s 170us/step - loss: 667795.8353 - mse: 667795.8125\n",
      "Epoch 431/500\n",
      "1077/1077 [==============================] - 0s 137us/step - loss: 669039.2131 - mse: 669039.3750\n",
      "Epoch 432/500\n",
      "1077/1077 [==============================] - 0s 138us/step - loss: 669245.7570 - mse: 669245.8125\n",
      "Epoch 433/500\n",
      "1077/1077 [==============================] - 0s 177us/step - loss: 667324.6778 - mse: 667324.5625\n",
      "Epoch 434/500\n",
      "1077/1077 [==============================] - 0s 212us/step - loss: 668068.3963 - mse: 668068.4375\n",
      "Epoch 435/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077/1077 [==============================] - 0s 210us/step - loss: 667626.0697 - mse: 667626.0625\n",
      "Epoch 436/500\n",
      "1077/1077 [==============================] - 0s 208us/step - loss: 666995.7083 - mse: 666995.7500\n",
      "Epoch 437/500\n",
      "1077/1077 [==============================] - 0s 290us/step - loss: 665157.9343 - mse: 665158.0000\n",
      "Epoch 438/500\n",
      "1077/1077 [==============================] - 0s 162us/step - loss: 665577.7878 - mse: 665577.7500\n",
      "Epoch 439/500\n",
      "1077/1077 [==============================] - 0s 205us/step - loss: 664121.2649 - mse: 664121.3125\n",
      "Epoch 440/500\n",
      "1077/1077 [==============================] - 0s 144us/step - loss: 664215.8562 - mse: 664215.8750\n",
      "Epoch 441/500\n",
      "1077/1077 [==============================] - 0s 144us/step - loss: 663779.6170 - mse: 663779.5625\n",
      "Epoch 442/500\n",
      "1077/1077 [==============================] - 0s 209us/step - loss: 663401.6398 - mse: 663401.6875\n",
      "Epoch 443/500\n",
      "1077/1077 [==============================] - 0s 162us/step - loss: 661918.2576 - mse: 661918.3750\n",
      "Epoch 444/500\n",
      "1077/1077 [==============================] - 0s 134us/step - loss: 663321.2622 - mse: 663321.1250\n",
      "Epoch 445/500\n",
      "1077/1077 [==============================] - 0s 203us/step - loss: 662352.8232 - mse: 662352.9375\n",
      "Epoch 446/500\n",
      "1077/1077 [==============================] - 0s 163us/step - loss: 662508.3472 - mse: 662508.1250\n",
      "Epoch 447/500\n",
      "1077/1077 [==============================] - 0s 235us/step - loss: 663012.2318 - mse: 663012.2500\n",
      "Epoch 448/500\n",
      "1077/1077 [==============================] - 0s 202us/step - loss: 661409.2898 - mse: 661409.3750\n",
      "Epoch 449/500\n",
      "1077/1077 [==============================] - 0s 160us/step - loss: 662630.9030 - mse: 662630.9375\n",
      "Epoch 450/500\n",
      "1077/1077 [==============================] - 0s 167us/step - loss: 662040.9387 - mse: 662040.8125\n",
      "Epoch 451/500\n",
      "1077/1077 [==============================] - 0s 170us/step - loss: 660123.8648 - mse: 660123.8750\n",
      "Epoch 452/500\n",
      "1077/1077 [==============================] - 0s 173us/step - loss: 660788.9943 - mse: 660789.1250\n",
      "Epoch 453/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 660905.0202 - mse: 660904.8750\n",
      "Epoch 454/500\n",
      "1077/1077 [==============================] - 0s 127us/step - loss: 659571.6170 - mse: 659571.6250\n",
      "Epoch 455/500\n",
      "1077/1077 [==============================] - 0s 121us/step - loss: 659301.6755 - mse: 659301.5625\n",
      "Epoch 456/500\n",
      "1077/1077 [==============================] - 0s 128us/step - loss: 660244.1320 - mse: 660243.8750\n",
      "Epoch 457/500\n",
      "1077/1077 [==============================] - 0s 134us/step - loss: 657359.3453 - mse: 657359.3750\n",
      "Epoch 458/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 657317.5360 - mse: 657317.4375\n",
      "Epoch 459/500\n",
      "1077/1077 [==============================] - 0s 143us/step - loss: 659077.3947 - mse: 659077.2500\n",
      "Epoch 460/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 658814.0131 - mse: 658814.0000\n",
      "Epoch 461/500\n",
      "1077/1077 [==============================] - 0s 121us/step - loss: 656068.8581 - mse: 656068.7500\n",
      "Epoch 462/500\n",
      "1077/1077 [==============================] - 0s 163us/step - loss: 656155.6192 - mse: 656155.7500\n",
      "Epoch 463/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 655047.4997 - mse: 655047.4375\n",
      "Epoch 464/500\n",
      "1077/1077 [==============================] - 0s 135us/step - loss: 653497.8926 - mse: 653497.9375\n",
      "Epoch 465/500\n",
      "1077/1077 [==============================] - 0s 115us/step - loss: 658127.3819 - mse: 658127.4375\n",
      "Epoch 466/500\n",
      "1077/1077 [==============================] - 0s 143us/step - loss: 654399.4643 - mse: 654399.3750\n",
      "Epoch 467/500\n",
      "1077/1077 [==============================] - 0s 107us/step - loss: 653675.3370 - mse: 653675.4375\n",
      "Epoch 468/500\n",
      "1077/1077 [==============================] - 0s 115us/step - loss: 655359.1746 - mse: 655359.1875\n",
      "Epoch 469/500\n",
      "1077/1077 [==============================] - 0s 142us/step - loss: 656677.9369 - mse: 656677.9375\n",
      "Epoch 470/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 654419.5667 - mse: 654419.4375\n",
      "Epoch 471/500\n",
      "1077/1077 [==============================] - 0s 125us/step - loss: 652266.8003 - mse: 652266.8125\n",
      "Epoch 472/500\n",
      "1077/1077 [==============================] - 0s 155us/step - loss: 653783.8901 - mse: 653784.0000\n",
      "Epoch 473/500\n",
      "1077/1077 [==============================] - 0s 138us/step - loss: 653795.1646 - mse: 653795.0625\n",
      "Epoch 474/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 653046.2393 - mse: 653046.3125\n",
      "Epoch 475/500\n",
      "1077/1077 [==============================] - 0s 133us/step - loss: 651716.8333 - mse: 651716.9375\n",
      "Epoch 476/500\n",
      "1077/1077 [==============================] - 0s 176us/step - loss: 652711.0384 - mse: 652711.1250\n",
      "Epoch 477/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 652780.2523 - mse: 652780.0625\n",
      "Epoch 478/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 648965.3365 - mse: 648965.4375\n",
      "Epoch 479/500\n",
      "1077/1077 [==============================] - 0s 113us/step - loss: 651055.0945 - mse: 651055.1875\n",
      "Epoch 480/500\n",
      "1077/1077 [==============================] - 0s 115us/step - loss: 650396.6229 - mse: 650396.5000\n",
      "Epoch 481/500\n",
      "1077/1077 [==============================] - 0s 136us/step - loss: 650731.1461 - mse: 650731.3125\n",
      "Epoch 482/500\n",
      "1077/1077 [==============================] - 0s 122us/step - loss: 648308.8865 - mse: 648309.0000\n",
      "Epoch 483/500\n",
      "1077/1077 [==============================] - 0s 143us/step - loss: 648755.8439 - mse: 648755.7500\n",
      "Epoch 484/500\n",
      "1077/1077 [==============================] - 0s 117us/step - loss: 647509.0222 - mse: 647509.1250\n",
      "Epoch 485/500\n",
      "1077/1077 [==============================] - 0s 126us/step - loss: 648095.7012 - mse: 648095.6875\n",
      "Epoch 486/500\n",
      "1077/1077 [==============================] - 0s 132us/step - loss: 647998.6681 - mse: 647998.6250\n",
      "Epoch 487/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 648117.4965 - mse: 648117.5625\n",
      "Epoch 488/500\n",
      "1077/1077 [==============================] - 0s 132us/step - loss: 646594.8247 - mse: 646594.8750\n",
      "Epoch 489/500\n",
      "1077/1077 [==============================] - 0s 125us/step - loss: 648252.8855 - mse: 648252.8750\n",
      "Epoch 490/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 646330.5930 - mse: 646330.5000\n",
      "Epoch 491/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 645612.4449 - mse: 645612.5000\n",
      "Epoch 492/500\n",
      "1077/1077 [==============================] - 0s 174us/step - loss: 644334.2646 - mse: 644334.1875\n",
      "Epoch 493/500\n",
      "1077/1077 [==============================] - 0s 110us/step - loss: 645009.0314 - mse: 645009.1250\n",
      "Epoch 494/500\n",
      "1077/1077 [==============================] - 0s 108us/step - loss: 644864.3145 - mse: 644864.2500\n",
      "Epoch 495/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 646904.9730 - mse: 646904.7500\n",
      "Epoch 496/500\n",
      "1077/1077 [==============================] - 0s 136us/step - loss: 646473.8761 - mse: 646473.8750\n",
      "Epoch 497/500\n",
      "1077/1077 [==============================] - 0s 126us/step - loss: 645980.4505 - mse: 645980.3750\n",
      "Epoch 498/500\n",
      "1077/1077 [==============================] - 0s 109us/step - loss: 643700.7116 - mse: 643700.6875\n",
      "Epoch 499/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 642923.0018 - mse: 642923.0625\n",
      "Epoch 500/500\n",
      "1077/1077 [==============================] - 0s 111us/step - loss: 642877.1209 - mse: 642877.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2561c71ba88>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(X_train,y_train,epochs=500, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/359 [==============================] - 0s 64us/step\n",
      "\u001b[1m \u001b[91m \n",
      "RNN Scores :\u001b[00m\n",
      "Train Score --> 0.9511968672357237\n",
      "Test Score  --> 0.8596356894515929\n"
     ]
    }
   ],
   "source": [
    "rnn.evaluate(X_test,y_test)\n",
    "\n",
    "y_train_pred = rnn.predict(X_train)\n",
    "y_test_pred = rnn.predict(X_test)\n",
    "\n",
    "prRed(\"\\nRNN Scores :\")\n",
    "print(\"Train Score -->\", r2_score(y_train_pred,y_train))\n",
    "print(\"Test Score  -->\", r2_score(y_test_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(\n",
       "    [\"base/js/dialog\"], \n",
       "    function(dialog) {\n",
       "        dialog.modal({\n",
       "            title: 'Project_2_Regression Summary',\n",
       "            body: 'Looking at post PCA scores, Linear regression has the highest score.',\n",
       "            buttons: {\n",
       "                'Best Model is yet again Linear!!': {}\n",
       "            }\n",
       "        });\n",
       "    })\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "display(Javascript(\"\"\"\n",
    "require(\n",
    "    [\"base/js/dialog\"], \n",
    "    function(dialog) {\n",
    "        dialog.modal({\n",
    "            title: 'Project_2_Regression Summary',\n",
    "            body: 'Looking at post PCA scores, Linear regression has the highest score.',\n",
    "            buttons: {\n",
    "                'Best Model is yet again Linear!!': {}\n",
    "            }\n",
    "        });\n",
    "    })\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
